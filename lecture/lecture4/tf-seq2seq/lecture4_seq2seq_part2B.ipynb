{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演示seq2seq lib中的beam search使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\reade\\\\Documents\\\\lecture4\\\\seq2seq')\n",
    "from seq2seq.encoders import rnn_encoder\n",
    "from seq2seq.decoders import (basic_decoder, beam_search_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 产生/demo 合成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生10个长度不一（最短3，最长8）的sequences, 其中前十个是:\n",
      "[2, 6, 3, 4, 5]\n",
      "[8, 7, 3, 4]\n",
      "[9, 3, 8, 2]\n",
      "[5, 9, 9, 3, 4, 4, 8]\n",
      "[4, 2, 7, 9, 7, 6, 9, 6]\n",
      "[2, 4, 6, 9, 8, 9, 7]\n",
      "[9, 7, 6, 6, 7, 3]\n",
      "[5, 5, 9, 6, 8, 2, 8, 3]\n",
      "[8, 8, 3, 7]\n",
      "[7, 2, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 16\n",
    "\n",
    "encoder_hidden_units = 32\n",
    "decoder_hidden_units = encoder_hidden_units\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 10\n",
    "\n",
    "# 一个generator，每次产生一个minibatch的随机样本\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('产生%d个长度不一（最短3，最长8）的sequences, 其中前十个是:' % batch_size)\n",
    "for seq in next(batches)[:min(batch_size, 10)]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义使用beamsearch decoder的seq2seq模型\n",
    "\n",
    "### 声明placholder和定义encoder部分，同part2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating UnidirectionalRNNEncoder in mode=train\n",
      "INFO:tensorflow:\n",
      "UnidirectionalRNNEncoder:\n",
      "  init_scale: 0.04\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN\n",
    "\n",
    "with tf.name_scope('minibatch'):\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "\n",
    "    decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')\n",
    "    decoder_targets_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_targets_length')\n",
    "    \n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    decoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')\n",
    "\n",
    "    decoder_initial_state = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.float32,\n",
    "                                    name='decoder_initial_state')\n",
    "    \n",
    "\n",
    "# 2-a. 定义encoder\n",
    "encoder_params = rnn_encoder.UnidirectionalRNNEncoder.default_params()\n",
    "encoder_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = encoder_hidden_units\n",
    "encoder_params[\"rnn_cell\"][\"cell_class\"] = \"BasicLSTMCell\"\n",
    "encoder_params  \n",
    "\n",
    "# 2-b. 定义encoding过程\n",
    "# 输入数据转化为embedding格式\n",
    "with tf.name_scope('embedding'):\n",
    "    input_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "    output_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, encoder_inputs)\n",
    "\n",
    "# 使用UnidirectionalRNNEncoder编码\n",
    "encode_fn = rnn_encoder.UnidirectionalRNNEncoder(encoder_params, mode)\n",
    "encoder_output = encode_fn(encoder_inputs_embedded, encoder_inputs_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义decoding模型，使用seq2seq.decoders.beam_search_decoder.BeamSearchDecoder\n",
    "1. input embedding\n",
    "2. helper <-- decoder_input, decoder_input_length\n",
    "3. basic_decoder.BasicDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config decoder的选项，任何基于RNN的decoding操作都需要设定的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_scale': 0.04,\n",
       " 'max_decode_length': 100,\n",
       " 'rnn_cell': {'cell_class': 'BasicLSTMCell',\n",
       "  'cell_params': {'num_units': 32},\n",
       "  'dropout_input_keep_prob': 1.0,\n",
       "  'dropout_output_keep_prob': 1.0,\n",
       "  'num_layers': 1,\n",
       "  'residual_combiner': 'add',\n",
       "  'residual_connections': False,\n",
       "  'residual_dense': False}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_params = beam_search_decoder.BeamSearchDecoder.default_params()\n",
    "decode_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = decoder_hidden_units\n",
    "decode_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config beam_search的选项，即beam_search操作的超参数\n",
    "\n",
    "* beam_width\n",
    "* length_penalty_weight\n",
    "* choose_successors_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchConfig(beam_width=10, vocab_size=10, eos_token=1, length_penalty_weight=0.6, choose_successors_fn=<function choose_top_k at 0x000002328DBFDEA0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seq2seq.inference import beam_search\n",
    "config = beam_search.BeamSearchConfig(\n",
    "    beam_width = 10,\n",
    "    vocab_size = vocab_size,\n",
    "    eos_token = EOS,\n",
    "    length_penalty_weight = 0.6,\n",
    "    choose_successors_fn = beam_search.choose_top_k)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq.contrib.seq2seq import helper as decode_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n",
      "INFO:tensorflow:Creating BeamSearchDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BeamSearchDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_helper = decode_helper.GreedyEmbeddingHelper(\n",
    "    embedding=output_embeddings,\n",
    "    start_tokens=[0] * config.beam_width,\n",
    "    end_token=-1)\n",
    "\n",
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)\n",
    "\n",
    "\"\"\"\n",
    "decoder_fn = create_decoder(\n",
    "    helper=beam_helper,\n",
    "    mode=tf.contrib.learn.ModeKeys.INFER)\n",
    "\"\"\"\n",
    "decoder_fn = beam_search_decoder.BeamSearchDecoder(\n",
    "    decoder=decoder_fn,\n",
    "    config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch'):\n",
    "    helper = decode_helper.TrainingHelper(\n",
    "        inputs = decoder_inputs_embedded,\n",
    "        sequence_length = decoder_inputs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, decoder_state = decoder_fn(encoder_output.final_state, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32), \n",
    "        logits=tf.transpose(decoder_output.logits, perm = [1, 0, 2]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# 通过阅读decoder_helper的定义，\n",
    "# 输入数据是batch-major\n",
    "# 而输出数据是time-major...\n",
    "# 所以需要对输出的logits做一次transpose\n",
    "# labels: [batch_size, max_length, vocab_size]\n",
    "# logits （tranpose之前）: [max_length, batch_size, vocab_size] \n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits = tf.transpose(decoder_output.logits, perm=[1,0,2]), labels = decoder_targets))\n",
    "\"\"\"\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, decoder_targets_length_ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_,\n",
    "        decoder_targets_length: decoder_targets_length_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'minibatch/encoder_inputs:0' shape=(?, ?) dtype=int32>: array([[6, 9, 8, 3, 9, 0, 0],\n",
       "        [5, 6, 5, 7, 7, 6, 7],\n",
       "        [2, 9, 6, 2, 8, 2, 0],\n",
       "        [6, 2, 8, 9, 8, 0, 0],\n",
       "        [2, 8, 7, 4, 0, 0, 0],\n",
       "        [2, 9, 4, 9, 0, 0, 0],\n",
       "        [9, 2, 2, 4, 5, 0, 0],\n",
       "        [7, 5, 3, 3, 7, 0, 0],\n",
       "        [4, 4, 7, 0, 0, 0, 0],\n",
       "        [7, 9, 3, 9, 2, 0, 0]]),\n",
       " <tf.Tensor 'minibatch/decoder_inputs:0' shape=(?, ?) dtype=int32>: array([[1, 6, 9, 8, 3, 9, 0, 0],\n",
       "        [1, 5, 6, 5, 7, 7, 6, 7],\n",
       "        [1, 2, 9, 6, 2, 8, 2, 0],\n",
       "        [1, 6, 2, 8, 9, 8, 0, 0],\n",
       "        [1, 2, 8, 7, 4, 0, 0, 0],\n",
       "        [1, 2, 9, 4, 9, 0, 0, 0],\n",
       "        [1, 9, 2, 2, 4, 5, 0, 0],\n",
       "        [1, 7, 5, 3, 3, 7, 0, 0],\n",
       "        [1, 4, 4, 7, 0, 0, 0, 0],\n",
       "        [1, 7, 9, 3, 9, 2, 0, 0]]),\n",
       " <tf.Tensor 'minibatch/encoder_inputs_length:0' shape=(?,) dtype=int32>: [5,\n",
       "  7,\n",
       "  6,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  5],\n",
       " <tf.Tensor 'minibatch/decoder_targets_length:0' shape=(?,) dtype=int32>: [6,\n",
       "  8,\n",
       "  7,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  4,\n",
       "  6],\n",
       " <tf.Tensor 'minibatch/decoder_targets:0' shape=(?, ?) dtype=int32>: array([[6, 9, 8, 3, 9, 1, 0, 0],\n",
       "        [5, 6, 5, 7, 7, 6, 7, 1],\n",
       "        [2, 9, 6, 2, 8, 2, 1, 0],\n",
       "        [6, 2, 8, 9, 8, 1, 0, 0],\n",
       "        [2, 8, 7, 4, 1, 0, 0, 0],\n",
       "        [2, 9, 4, 9, 1, 0, 0, 0],\n",
       "        [9, 2, 2, 4, 5, 1, 0, 0],\n",
       "        [7, 5, 3, 3, 7, 1, 0, 0],\n",
       "        [4, 4, 7, 1, 0, 0, 0, 0],\n",
       "        [7, 9, 3, 9, 2, 1, 0, 0]]),\n",
       " <tf.Tensor 'minibatch/decoder_inputs_length:0' shape=(?,) dtype=int32>: [6,\n",
       "  8,\n",
       "  7,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  4,\n",
       "  6]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd= next_feed()\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[encoder_inputs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[decoder_inputs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[decoder_targets].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 我们已经定义了一个计算图\n",
    "* 图的输入端是encoder_inputs 和 encoder_inputs_length\n",
    "* 图的输出端是encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoder_out1, decoder_out1] = sess.run(\n",
    "    [encoder_output, decoder_output], fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out1.outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.cell_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.predicted_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output information:\n",
      "(10, 7, 32)\n",
      "(10, 32)\n",
      "(10, 32)\n"
     ]
    }
   ],
   "source": [
    "print('encoder output information:')\n",
    "print(encoder_out1.outputs.shape)\n",
    "print(encoder_out1.final_state.c.shape)\n",
    "print(encoder_out1.final_state.h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder output information:\n",
      "(8, 10)\n"
     ]
    }
   ],
   "source": [
    "print('decoder output information:')\n",
    "print(decoder_out1.predicted_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.predicted_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:\n",
      "[3 2 6 2 0 0 0 0]\n",
      "decoder_inputs:\n",
      "[1 3 2 6 2 0 0 0 0]\n",
      "decoder_targets:\n",
      "[3 2 6 2 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x = next_feed()\n",
    "print('encoder_inputs:')\n",
    "print(x[encoder_inputs][0,:])\n",
    "print('decoder_inputs:')\n",
    "print(x[decoder_inputs][0,:])\n",
    "print('decoder_targets:')\n",
    "print(x[decoder_targets][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生100个长度不一的sequence\n",
      "其中前十个是:\n",
      "[2, 4, 2, 9, 2, 3]\n",
      "[5, 9, 2, 4]\n",
      "[6, 5, 6, 9, 3, 6, 6]\n",
      "[2, 9, 8, 4, 6, 9, 4]\n",
      "[8, 9, 7]\n",
      "[6, 6, 4, 4, 8, 6, 4]\n",
      "[5, 3, 3]\n",
      "[6, 8, 8, 4, 3]\n",
      "[9, 4, 3, 9, 2, 7]\n",
      "[5, 2, 3, 5, 9, 7, 6, 4]\n"
     ]
    }
   ],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, _ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_\n",
    "    }\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                        vocab_lower=2, vocab_upper=10,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "print('产生100个长度不一的sequence')\n",
    "print('其中前十个是:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.2923030853271484\n",
      "  sample 1:\n",
      "    input     > [8 3 9 2 6 0 0 0]\n",
      "    predicted > [8 0 0 0 0 0 5 5 5]\n",
      "  sample 2:\n",
      "    input     > [8 8 4 7 3 2 5 7]\n",
      "    predicted > [7 0 0 0 0 8 0 0 9]\n",
      "  sample 3:\n",
      "    input     > [6 5 3 6 0 0 0 0]\n",
      "    predicted > [3 3 3 8 2 5 5 5 5]\n",
      "\n",
      "batch 100\n",
      "  minibatch loss: 1.3723019361495972\n",
      "  sample 1:\n",
      "    input     > [9 9 8 9 9 0 0 0]\n",
      "    predicted > [9 9 9 9 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 4 7 0 0 0 0 0]\n",
      "    predicted > [5 9 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 6 9 2 7 0 0 0]\n",
      "    predicted > [9 9 9 1 1 1 0 0 0]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 0.9069716930389404\n",
      "  sample 1:\n",
      "    input     > [6 4 5 6 8 6 7 0]\n",
      "    predicted > [6 6 6 6 6 6 7 1 0]\n",
      "  sample 2:\n",
      "    input     > [5 8 4 8 6 9 3 0]\n",
      "    predicted > [8 8 4 8 3 3 3 1 0]\n",
      "  sample 3:\n",
      "    input     > [2 8 3 5 2 7 7 9]\n",
      "    predicted > [7 7 7 7 7 7 7 1 1]\n",
      "\n",
      "batch 300\n",
      "  minibatch loss: 0.5865991115570068\n",
      "  sample 1:\n",
      "    input     > [5 3 9 3 0 0 0 0]\n",
      "    predicted > [3 3 9 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 2 3 8 0 0 0 0]\n",
      "    predicted > [3 2 3 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 5 8 0 0 0 0 0]\n",
      "    predicted > [5 8 8 1 0 0 0 0 0]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 0.5036051869392395\n",
      "  sample 1:\n",
      "    input     > [8 9 4 7 8 9 0 0]\n",
      "    predicted > [8 9 4 8 8 9 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 6 7 2 4 8 2 0]\n",
      "    predicted > [7 7 2 2 4 2 2 1 0]\n",
      "  sample 3:\n",
      "    input     > [4 4 3 9 7 0 0 0]\n",
      "    predicted > [4 4 3 9 7 1 0 0 0]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 0.35312727093696594\n",
      "  sample 1:\n",
      "    input     > [4 3 6 5 6 6 0 0]\n",
      "    predicted > [6 6 6 6 6 6 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 6 3 0 0 0 0 0]\n",
      "    predicted > [9 6 3 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 6 8 3 8 4 9 6]\n",
      "    predicted > [7 6 8 3 8 9 9 9 1]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 0.29844003915786743\n",
      "  sample 1:\n",
      "    input     > [5 8 6 3 8 4 6 7]\n",
      "    predicted > [8 8 6 3 8 4 6 7 1]\n",
      "  sample 2:\n",
      "    input     > [3 8 6 9 8 0 0 0]\n",
      "    predicted > [6 8 6 9 8 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 9 4 8 8 0 0 0]\n",
      "    predicted > [6 9 8 8 8 1 0 0 0]\n",
      "\n",
      "batch 700\n",
      "  minibatch loss: 0.2059081494808197\n",
      "  sample 1:\n",
      "    input     > [2 7 2 9 5 6 0 0]\n",
      "    predicted > [2 7 2 9 5 6 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 6 2 9 7 0 0 0]\n",
      "    predicted > [9 6 2 9 7 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 7 7 2 9 9 4 0]\n",
      "    predicted > [7 7 7 9 9 9 4 1 0]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 0.23277786374092102\n",
      "  sample 1:\n",
      "    input     > [6 3 5 0 0 0 0 0]\n",
      "    predicted > [6 3 5 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 6 5 5 7 8 2 0]\n",
      "    predicted > [3 5 5 5 7 2 2 1 0]\n",
      "  sample 3:\n",
      "    input     > [6 6 3 3 0 0 0 0]\n",
      "    predicted > [6 3 3 3 1 0 0 0 0]\n",
      "\n",
      "batch 900\n",
      "  minibatch loss: 0.20536023378372192\n",
      "  sample 1:\n",
      "    input     > [6 7 3 3 2 0 0 0]\n",
      "    predicted > [3 3 3 3 2 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 5 6 6 7 6 3 0]\n",
      "    predicted > [9 6 6 6 7 3 3 1 0]\n",
      "  sample 3:\n",
      "    input     > [8 9 9 6 9 6 0 0]\n",
      "    predicted > [9 9 9 6 9 6 1 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.16776493191719055\n",
      "  sample 1:\n",
      "    input     > [4 9 9 4 0 0 0 0]\n",
      "    predicted > [4 9 9 4 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 4 7 4 8 4 6 0]\n",
      "    predicted > [8 4 4 4 8 4 6 1 0]\n",
      "  sample 3:\n",
      "    input     > [2 4 4 7 8 7 8 7]\n",
      "    predicted > [4 4 4 7 8 7 8 1 1]\n",
      "\n",
      "batch 1100\n",
      "  minibatch loss: 0.1620839536190033\n",
      "  sample 1:\n",
      "    input     > [7 4 2 8 3 7 0 0]\n",
      "    predicted > [7 4 2 8 3 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 9 2 4 5 8 0 0]\n",
      "    predicted > [4 9 2 4 5 8 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 6 6 4 3 3 0 0]\n",
      "    predicted > [9 6 6 3 3 3 1 0 0]\n",
      "\n",
      "batch 1200\n",
      "  minibatch loss: 0.13824613392353058\n",
      "  sample 1:\n",
      "    input     > [6 4 9 5 5 6 6 8]\n",
      "    predicted > [6 4 9 5 6 6 6 8 1]\n",
      "  sample 2:\n",
      "    input     > [9 8 2 0 0 0 0 0]\n",
      "    predicted > [9 8 2 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 7 2 2 5 0 0 0]\n",
      "    predicted > [9 2 2 2 5 1 0 0 0]\n",
      "\n",
      "batch 1300\n",
      "  minibatch loss: 0.15417630970478058\n",
      "  sample 1:\n",
      "    input     > [4 3 2 0 0 0 0 0]\n",
      "    predicted > [4 3 2 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 3 4 0 0 0 0 0]\n",
      "    predicted > [4 3 4 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 8 4 6 8 6 7 9]\n",
      "    predicted > [4 8 4 6 8 6 7 9 1]\n",
      "\n",
      "batch 1400\n",
      "  minibatch loss: 0.09418705850839615\n",
      "  sample 1:\n",
      "    input     > [7 5 3 0 0 0 0 0]\n",
      "    predicted > [7 5 3 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 6 7 0 0 0 0 0]\n",
      "    predicted > [9 6 7 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 9 5 0 0 0 0 0]\n",
      "    predicted > [4 9 5 1 0 0 0 0 0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 0.12240128964185715\n",
      "  sample 1:\n",
      "    input     > [4 4 6 0 0 0 0 0]\n",
      "    predicted > [4 4 6 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 4 7 8 2 0 0 0]\n",
      "    predicted > [6 4 7 8 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 3 2 9 8 6 7 0]\n",
      "    predicted > [7 3 2 9 8 6 7 1 0]\n",
      "\n",
      "batch 1600\n",
      "  minibatch loss: 0.10478095710277557\n",
      "  sample 1:\n",
      "    input     > [2 3 9 8 8 9 8 0]\n",
      "    predicted > [2 3 9 8 8 9 3 1 0]\n",
      "  sample 2:\n",
      "    input     > [3 6 3 9 0 0 0 0]\n",
      "    predicted > [3 6 3 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 8 5 4 0 0 0]\n",
      "    predicted > [4 2 8 5 4 1 0 0 0]\n",
      "\n",
      "batch 1700\n",
      "  minibatch loss: 0.09616126865148544\n",
      "  sample 1:\n",
      "    input     > [3 5 4 6 2 0 0 0]\n",
      "    predicted > [3 5 4 6 2 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 2 8 0 0 0 0 0]\n",
      "    predicted > [4 2 8 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 8 2 0 0 0 0 0]\n",
      "    predicted > [7 8 2 1 0 0 0 0 0]\n",
      "\n",
      "batch 1800\n",
      "  minibatch loss: 0.10523340106010437\n",
      "  sample 1:\n",
      "    input     > [7 3 8 0 0 0 0 0]\n",
      "    predicted > [7 3 8 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 5 8 3 0 0 0 0]\n",
      "    predicted > [9 5 8 3 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 7 7 5 8 2 4 9]\n",
      "    predicted > [6 7 7 5 8 2 4 9 1]\n",
      "\n",
      "batch 1900\n",
      "  minibatch loss: 0.08575332909822464\n",
      "  sample 1:\n",
      "    input     > [7 8 6 9 4 0 0 0]\n",
      "    predicted > [7 8 6 9 4 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 3 5 3 0 0 0 0]\n",
      "    predicted > [2 3 5 3 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 5 8 6 7 2 0 0]\n",
      "    predicted > [7 5 8 6 7 2 1 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.07463198155164719\n",
      "  sample 1:\n",
      "    input     > [7 4 3 4 8 8 3 0]\n",
      "    predicted > [7 4 3 4 8 8 3 1 0]\n",
      "  sample 2:\n",
      "    input     > [5 5 2 0 0 0 0 0]\n",
      "    predicted > [5 5 2 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 5 4 4 9 4 6 3]\n",
      "    predicted > [5 5 4 4 9 6 6 3 1]\n",
      "\n",
      "batch 2100\n",
      "  minibatch loss: 0.07581789791584015\n",
      "  sample 1:\n",
      "    input     > [7 3 3 4 3 0 0 0]\n",
      "    predicted > [7 3 3 4 3 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 5 2 8 3 0 0 0]\n",
      "    predicted > [5 5 2 8 3 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 2 7 3 2 0 0 0]\n",
      "    predicted > [5 2 7 3 2 1 0 0 0]\n",
      "\n",
      "batch 2200\n",
      "  minibatch loss: 0.08387318253517151\n",
      "  sample 1:\n",
      "    input     > [7 6 2 9 2 0 0 0]\n",
      "    predicted > [7 6 2 9 2 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 6 4 0 0 0 0 0]\n",
      "    predicted > [5 6 4 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 4 7 9 8 8 9 9]\n",
      "    predicted > [4 4 7 9 8 9 9 9 1]\n",
      "\n",
      "batch 2300\n",
      "  minibatch loss: 0.06899324059486389\n",
      "  sample 1:\n",
      "    input     > [5 4 9 3 0 0 0 0]\n",
      "    predicted > [5 4 9 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 4 9 0 0 0 0 0]\n",
      "    predicted > [5 4 9 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 4 9 4 8 6 0 0]\n",
      "    predicted > [6 4 9 4 8 6 1 0 0]\n",
      "\n",
      "batch 2400\n",
      "  minibatch loss: 0.06299485266208649\n",
      "  sample 1:\n",
      "    input     > [2 8 7 0 0 0 0 0]\n",
      "    predicted > [2 8 7 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 4 2 8 3 7 7 0]\n",
      "    predicted > [9 4 2 8 3 7 7 1 0]\n",
      "  sample 3:\n",
      "    input     > [6 9 8 9 6 7 3 0]\n",
      "    predicted > [6 9 8 9 6 7 3 1 0]\n",
      "\n",
      "batch 2500\n",
      "  minibatch loss: 0.06577910482883453\n",
      "  sample 1:\n",
      "    input     > [4 9 6 7 2 5 7 7]\n",
      "    predicted > [4 9 6 7 2 5 7 7 1]\n",
      "  sample 2:\n",
      "    input     > [6 2 5 8 7 4 7 0]\n",
      "    predicted > [6 2 5 8 7 4 7 1 0]\n",
      "  sample 3:\n",
      "    input     > [9 4 7 8 5 7 8 7]\n",
      "    predicted > [9 4 7 8 7 7 7 7 1]\n",
      "\n",
      "batch 2600\n",
      "  minibatch loss: 0.058884985744953156\n",
      "  sample 1:\n",
      "    input     > [5 2 6 7 9 6 4 2]\n",
      "    predicted > [5 2 6 7 9 6 4 2 1]\n",
      "  sample 2:\n",
      "    input     > [6 6 3 7 2 2 0 0]\n",
      "    predicted > [6 6 3 7 2 2 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 5 8 2 8 9 5 5]\n",
      "    predicted > [5 5 8 2 8 5 5 5 1]\n",
      "\n",
      "batch 2700\n",
      "  minibatch loss: 0.05661299079656601\n",
      "  sample 1:\n",
      "    input     > [2 6 7 2 3 2 7 9]\n",
      "    predicted > [2 6 7 2 3 2 7 9 1]\n",
      "  sample 2:\n",
      "    input     > [7 5 9 9 0 0 0 0]\n",
      "    predicted > [7 5 9 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 4 6 0 0 0 0 0]\n",
      "    predicted > [4 4 6 1 0 0 0 0 0]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2800\n",
      "  minibatch loss: 0.04671445116400719\n",
      "  sample 1:\n",
      "    input     > [4 3 5 4 2 8 0 0]\n",
      "    predicted > [4 3 5 4 2 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 3 9 8 8 6 9 8]\n",
      "    predicted > [4 3 9 8 8 6 9 8 1]\n",
      "  sample 3:\n",
      "    input     > [6 3 2 6 0 0 0 0]\n",
      "    predicted > [6 3 2 6 1 0 0 0 0]\n",
      "\n",
      "batch 2900\n",
      "  minibatch loss: 0.06657446920871735\n",
      "  sample 1:\n",
      "    input     > [5 2 9 0 0 0 0 0]\n",
      "    predicted > [5 2 9 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 3 7 6 6 4 5 2]\n",
      "    predicted > [7 3 7 6 6 4 5 7 1]\n",
      "  sample 3:\n",
      "    input     > [7 7 6 3 4 0 0 0]\n",
      "    predicted > [7 7 6 3 4 1 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.04009970277547836\n",
      "  sample 1:\n",
      "    input     > [2 3 5 3 0 0 0 0]\n",
      "    predicted > [2 3 5 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 6 4 7 9 6 9 2]\n",
      "    predicted > [4 6 4 9 9 6 9 2 1]\n",
      "  sample 3:\n",
      "    input     > [5 9 7 4 4 6 0 0]\n",
      "    predicted > [5 9 7 4 4 6 1 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 100\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_output.predicted_ids, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs], predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0427 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x232aa2519b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
