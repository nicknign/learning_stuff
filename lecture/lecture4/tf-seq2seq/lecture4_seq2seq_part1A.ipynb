{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这一部分演示使用dynamic_rnn实现简单的seq2seq模型\n",
    "主要参考 github repo [tensorflow-seq2seq-tutorial](https://github.com/ematvey/tensorflow-seq2seq-tutorials)的第一和第二部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 产生不定长合成序列的函数\n",
    "import helpers as data_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo-I：使用dynamic_rnn实现简单的seq2seq模型\n",
    "\n",
    "### 使用一个合成的minibatch data解释seq2seq模型\n",
    "\n",
    "### seq2seq模型任务是copy sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 合成数据\n",
    "\n",
    "**seq2seq模型中的数据特征：不定长度的序列样本**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [[5, 7, 8], [6, 3], [3], [1]]\n",
    "xt, xlen = data_helpers.batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始的4个序列样本是:\n",
      "[[5, 7, 8], [6, 3], [3], [1]]\n",
      "\n",
      "padding以后使用time-major记录的数据array: \n",
      "[[5 6 3 1]\n",
      " [7 3 0 0]\n",
      " [8 0 0 0]]\n",
      "\n",
      "padding以后使用batch-major记录的数据array: \n",
      "[[5 7 8]\n",
      " [6 3 0]\n",
      " [3 0 0]\n",
      " [1 0 0]]\n",
      "\n",
      "padding以后序列长度是: \n",
      " [3, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print('原始的4个序列样本是:\\n%s' % x)\n",
    "print('\\npadding以后使用time-major记录的数据array: \\n%s' % xt)\n",
    "print('\\npadding以后使用batch-major记录的数据array: \\n%s' % xt.T)\n",
    "print('\\npadding以后序列长度是: \\n %s' % xlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`InteractiveSession`**在 理解tf的函数 和 debug一段代码 方面非常有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = 2 * encoder_hidden_units # bidirectional RNN, 见后面的解释"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. placeholders,模型的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch'):\n",
    "    # encoding 阶段的 placeholder\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "\n",
    "    # decoding 阶段的placeholder\n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    \n",
    "    # decoding 结束后用来计算损失函数\n",
    "    decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/seq2seq2014.png)\n",
    "图片来自[Sutskever et al., 2014](https://arxiv.org/abs/1409.3215)\n",
    "\n",
    "**在这个图示的例子里面**\n",
    "* `encoder_inputs = ['A', 'B', 'C']`\n",
    "* `decoder_inputs = [<EOS>, 'W', 'X', 'Y', 'Z']`\n",
    "* `decoder_targets = ['W', 'X', 'Y', 'Z', <EOS>]`\n",
    "\n",
    "在图示的decoding阶段，每个时间，真实的sequence[t] 被提供给RNN-cell去预测 sequence[t+1]（近似于第二节课的RNNLM），**只适用于训练阶段**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('embedding'):\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoder\n",
    "使用dynamic_rnn将一个Mini-batch样本编码，只保留每一个sequence结尾处的state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三节课的代码里面已经演示了dynamic_rnn进行encoding：\n",
    "```python\n",
    "_, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell = encoder_cell,\n",
    "    inputs = encoder_inputs_embedded,\n",
    "    sequence_length = encoder_inputs_length,\n",
    "    dtype=tf.float32,\n",
    "    time_major=True,\n",
    ")\n",
    "```\n",
    "这里我们使用双向 `\n",
    "`:\n",
    "\n",
    "![alt text](figure/RNN-bidirectional.png)\n",
    "图片来自于[Colah的blog](http://colah.github.io/posts/2015-09-NN-Types-FP/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    (encoder_fw_outputs, encoder_bw_outputs), \n",
    "    (encoder_fw_final_state, encoder_bw_final_state)\n",
    ") = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw=encoder_cell,\n",
    "        cell_bw=encoder_cell,\n",
    "        inputs=encoder_inputs_embedded,\n",
    "        sequence_length=encoder_inputs_length,\n",
    "        dtype=tf.float32,\n",
    "        time_major=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前向和逆向lstm-RNN的final state拼接起来 （来自colah博客的图片演示了output的拼接）\n",
    "\n",
    "`final_state_c`, `final_state_h`\n",
    "\n",
    "从`[batch_size, numHidden]` 变成`[batch_size, 2*numHidden]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拼接前的前向和反向LSTM的状态Tensors\n",
      "\n",
      "前向:\n",
      "\tLSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32>)\n",
      "\n",
      "反向:\n",
      "\tLSTMStateTuple(c=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32>)\n",
      "\n",
      "拼接后的双向LSTM的状态Tensor:\n",
      "\tLSTMStateTuple(c=<tf.Tensor 'concat:0' shape=(?, 40) dtype=float32>, h=<tf.Tensor 'concat_1:0' shape=(?, 40) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "print('拼接前的前向和反向LSTM的状态Tensors')\n",
    "print('\\n前向:')\n",
    "print('\\t%s' % repr(encoder_fw_final_state))\n",
    "print('\\n反向:')\n",
    "print('\\t%s' % repr(encoder_bw_final_state))\n",
    "print('\\n拼接后的双向LSTM的状态Tensor:')\n",
    "print('\\t%s' % repr(encoder_final_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vanilla 版本 Decoder\n",
    "* 使用 **`minibatch`**个输入序列在 **`encoder`** RNN的 **`final-state`** 作为 **`decoder`** 的 **`initial-state`**\n",
    "* 使用 **`dynamic_rnn`** 将一个 **`minibatch`** 的**`final_state`** 解码为**`minibatch`** 个 输出序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在decoding阶段，我们不知道`sequence_length`的数值，即输出sequence的长度\n",
    "\n",
    "* 如果我们提供**`decoder_inputs`**, 则**`dynamic_rnn`**返回和**`inputs`**同样长度的**outputs**\n",
    "* **`decoder_inputs`**的长度和内容是一个non-trivial的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(decoder_hidden_units)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    cell = decoder_cell,\n",
    "    inputs = decoder_inputs_embedded,\n",
    "    initial_state=encoder_final_state,\n",
    "    dtype=tf.float32,\n",
    "    time_major=True,\n",
    "    scope=\"plain_decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, vocab_size)\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看decoder_logits的维度（最后一个维度是vocab_size）：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, ?, 10) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('查看decoder_logits的维度（最后一个维度是vocab_size）：')\n",
    "decoder_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算维度`[batch_size, maxT, vocab_size]`的`decoder_prediction` 和同样维度的解码目标`decoder_targets`之间的cross-entropy损失函数\n",
    "\n",
    "#### 这里需要注意一个问题，`<eos>`后面的`subsequence` 也会被用来计算loss\n",
    "\n",
    "以上图为例\n",
    "* 如果target是 `[W, X, Y, Z, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>]`\n",
    "* decoding结果是 `[W, X, Y, Z, <EOS>, Z, Y, Z, W]`\n",
    "\n",
    "衡量这两个sequence区别的cross entropy loss 应该是多少？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 运行forward-propagation\n",
    "\n",
    "**产生一个minibatch的sequence，实验`seq2seq model forward-propagation`，seq2seq模型的prediction任务是复制input sequence**\n",
    "\n",
    "* 在encoding阶段，我们只需要`input_sequence`\n",
    "* 在decoding阶段，我们通常需要使用两个变量\n",
    "  1. `decoder_input`： 作为RNN模型的底层输入数据，**内容见下面的例子**\n",
    "  2. `initial_state`： 作为RNN模型的初始状态，seq2seq模型里面，通常对应着encoder的final state\n",
    "* 在projection阶段：对`decoder_output`（RNN decoding模型运行的输出)通过一个linear projection预测单词ID\n",
    "* 在训练阶段，projection结束后，我们还需要一个变量来计算损失函数\n",
    "  3. `decoder_target`： 用来和decoder_output预测的单词sequence比较，计算prediction的准确性。在我们的复制任务里面，等于 `input_sequence` + `<eos>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生100个长度不一的sequence\n",
      "其中前十个是:\n",
      "[4, 9, 4]\n",
      "[9, 4, 3, 9, 5]\n",
      "[2, 7, 2, 8, 8, 2, 3, 2]\n",
      "[6, 9, 6, 5, 3, 2, 3]\n",
      "[6, 5, 6, 4, 4, 4, 7]\n",
      "[3, 8, 6, 9, 6]\n",
      "[9, 9, 3, 5, 5, 9, 2]\n",
      "[3, 7, 9, 4]\n",
      "[2, 7, 7, 6, 4, 8]\n",
      "[6, 4, 3, 9, 7]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                        vocab_lower=2, vocab_upper=10,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "print('产生100个长度不一的sequence')\n",
    "print('其中前十个是:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)\n",
    "\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, _ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, _ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs: decoder_inputs_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:\n",
      "[6 2 9 4 9 3 0 0]\n",
      "encoder_inputs_length:\n",
      "6\n",
      "decoder_inputs:\n",
      "[1 6 2 9 4 9 3 0 0]\n",
      "decoder_targets:\n",
      "[6 2 9 4 9 3 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "x = next_feed()\n",
    "print('encoder_inputs:')\n",
    "print(x[encoder_inputs][:,0].T)\n",
    "print('encoder_inputs_length:')\n",
    "print(x[encoder_inputs_length][0])\n",
    "print('decoder_inputs:')\n",
    "print(x[decoder_inputs][:,0].T)\n",
    "print('decoder_targets:')\n",
    "print(x[decoder_targets][:,0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred, _, l = sess.run([decoder_prediction, train_op, loss], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_targets\n",
      "[[6 2 9 4 9 3 1 0 0]\n",
      " [4 5 3 3 8 4 7 5 1]\n",
      " [8 3 5 4 9 6 5 6 1]\n",
      " [6 9 5 9 3 2 4 1 0]\n",
      " [9 9 7 7 3 4 6 4 1]]\n",
      "decoder_inputs\n",
      "[[1 6 2 9 4 9 3 0 0]\n",
      " [1 4 5 3 3 8 4 7 5]\n",
      " [1 8 3 5 4 9 6 5 6]\n",
      " [1 6 9 5 9 3 2 4 0]\n",
      " [1 9 9 7 7 3 4 6 4]]\n",
      "prediction\n",
      "[[8 5 8 8 5 5 8 8 8]\n",
      " [8 9 9 5 8 4 4 5 3]\n",
      " [9 9 8 4 9 0 9 9 9]\n",
      " [8 1 8 5 6 8 8 2 2]\n",
      " [1 8 8 8 1 8 1 1 5]]\n"
     ]
    }
   ],
   "source": [
    "print('decoder_targets')\n",
    "print(x[decoder_targets][:,0:5].T)\n",
    "\n",
    "print('decoder_inputs')\n",
    "print(x[decoder_inputs][:,0:5].T)\n",
    "\n",
    "print('prediction')\n",
    "print(pred[:,0:5].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "几个训练用的样本和输出的结果，注意三者的区别\n",
    "\n",
    "```\n",
    "decoder_targets\n",
    "[[9 8 6 1 0 0 0 0 0]\n",
    " [8 3 4 7 1 0 0 0 0]\n",
    " [6 2 6 4 6 4 4 3 1]\n",
    " [3 7 6 5 5 8 1 0 0]\n",
    " [6 9 4 7 1 0 0 0 0]]\n",
    "decoder_inputs\n",
    "[[1 9 8 6 0 0 0 0 0]\n",
    " [1 8 3 4 7 0 0 0 0]\n",
    " [1 6 2 6 4 6 4 4 3]\n",
    " [1 3 7 6 5 5 8 0 0]\n",
    " [1 6 9 4 7 0 0 0 0]]\n",
    "prediction\n",
    "[[2 2 2 7 2 2 2 2 2]\n",
    " [2 2 2 1 0 2 2 2 2]\n",
    " [4 4 4 7 7 7 7 7 7]\n",
    " [2 1 1 7 2 0 0 2 2]\n",
    " [2 2 4 7 7 7 6 2 2]]\n",
    "\n",
    "```\n",
    "\n",
    "* 在这里我们将真实的input shift以后作为decoding 的 input\n",
    "\n",
    "* 在下一个实验里面，将要讨论**`decoder_input`**的其他选项\n",
    "\n",
    "![alt text](figure/seq2seq2014.png)\n",
    "再次引用此图，和上面的训练用的样本对应\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo-II：训练使用(bidirectional-)dynamic_rnn的简单的seq2seq模型\n",
    "\n",
    "相对于demo-I增加optimization部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 将 encoding 和 decoding 数据输入计算图，得到预测的词语sequence\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    pred_, loss = session.run([decoder_prediction, loss],\n",
    "        feed_dict={\n",
    "            encoder_inputs: ein_,\n",
    "            encoder_inputs_length: ein_length_,\n",
    "            decoder_inputs: din_,\n",
    "            decoder_targets: dtar_\n",
    "        })\n",
    "\n",
    "    print('decoder predictions:\\n' + str(pred_))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.3010060787200928\n",
      "  sample 1:\n",
      "    input     > [2 3 9 5 5 0 0 0]\n",
      "    predicted > [8 8 8 8 4 4 3 3 2]\n",
      "  sample 2:\n",
      "    input     > [5 2 3 9 4 5 2 0]\n",
      "    predicted > [8 9 8 8 8 0 2 2 2]\n",
      "  sample 3:\n",
      "    input     > [5 7 8 0 0 0 0 0]\n",
      "    predicted > [8 7 5 3 3 3 1 1 1]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.20259717106819153\n",
      "  sample 1:\n",
      "    input     > [6 5 9 5 2 8 0 0]\n",
      "    predicted > [6 5 9 5 2 8 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [9 4 2 5 2 8 0 0]\n",
      "    predicted > [9 4 2 5 2 8 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 5 9 0 0 0 0 0]\n",
      "    predicted > [9 5 9 1 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.08791466057300568\n",
      "  sample 1:\n",
      "    input     > [2 7 3 3 5 5 5 0]\n",
      "    predicted > [2 7 3 3 5 5 5 1 0]\n",
      "  sample 2:\n",
      "    input     > [3 9 4 6 7 5 4 5]\n",
      "    predicted > [3 9 6 6 7 5 4 5 1]\n",
      "  sample 3:\n",
      "    input     > [2 6 7 4 3 7 2 2]\n",
      "    predicted > [6 6 7 4 7 7 2 2 1]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.03814181312918663\n",
      "  sample 1:\n",
      "    input     > [4 7 6 8 0 0 0 0]\n",
      "    predicted > [4 7 6 8 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 5 2 5 3 5 0 0]\n",
      "    predicted > [6 5 2 5 3 5 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 6 2 6 9 7 7 9]\n",
      "    predicted > [2 6 2 6 9 7 7 9 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, _, l = sess.run([decoder_prediction, train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder output的长度问题\n",
    "\n",
    "* 和RNNLM不同，在seq2seq模型中，decoding阶段产生的序列的长度是未知的\n",
    "* 如何设定decoding序列的长度？\n",
    "* 可以设定decoding比encoding输入序列长NUM个单位，比较decoding prediction的`<eos>`之前的subsequence和真实的decoding_target的差别作为损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0493 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22564fd06d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
