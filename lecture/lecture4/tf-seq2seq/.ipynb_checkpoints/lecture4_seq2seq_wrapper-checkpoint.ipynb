{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理twitter对话数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['w2idx', 'limit', 'freq_dist', 'idx2w'])\n",
      "(267518, 20)\n",
      "(267518, 20)\n",
      "(267518, 40)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dirName = 'C:\\\\Users\\\\reade\\\\Documents\\\\lecture4\\\\twitter'\n",
    "fileName = os.path.join(dirName, 'metadata.pkl')\n",
    "\n",
    "import pickle\n",
    "with open(fileName, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(data.keys())\n",
    "\n",
    "npNameA = os.path.join(dirName, 'idx_a.npy')\n",
    "npNameQ = os.path.join(dirName, 'idx_q.npy')\n",
    "import numpy as np\n",
    "data_a = np.load(npNameA)\n",
    "data_q = np.load(npNameA)\n",
    "\n",
    "print(data_a.shape)\n",
    "print(data_q.shape)\n",
    "data_qa = np.concatenate([data_q, data_a], axis = 1)\n",
    "print(data_qa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle\n",
    "\n",
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, decoder_targets_length_ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_,\n",
    "        decoder_targets_length: decoder_targets_length_\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\reade\\\\Documents\\\\lecture4\\\\seq2seq')\n",
    "from seq2seq.encoders import rnn_encoder\n",
    "from seq2seq.decoders import (basic_decoder, beam_search_decoder)\n",
    "\n",
    "\n",
    "\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = len(data['w2idx'])\n",
    "input_embedding_size = 128\n",
    "\n",
    "encoder_hidden_units = 128\n",
    "decoder_hidden_units = encoder_hidden_units\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(267518, 20)\n",
      "(267518, 20)\n",
      "(267518, 40)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN\n",
    "\n",
    "with tf.name_scope('minibatch'):\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "\n",
    "    decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')\n",
    "    decoder_targets_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_targets_length')\n",
    "    \n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    decoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')\n",
    "\n",
    "    decoder_initial_state = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.float32,\n",
    "                                    name='decoder_initial_state')\n",
    "    \n",
    "\n",
    "# 2-a. 定义encoder\n",
    "encoder_params = rnn_encoder.UnidirectionalRNNEncoder.default_params()\n",
    "encoder_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = encoder_hidden_units\n",
    "encoder_params[\"rnn_cell\"][\"cell_class\"] = \"BasicLSTMCell\"\n",
    "encoder_params  \n",
    "\n",
    "# 2-b. 定义encoding过程\n",
    "# 输入数据转化为embedding格式\n",
    "with tf.name_scope('embedding'):\n",
    "    input_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "    output_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, encoder_inputs)\n",
    "\n",
    "# 使用UnidirectionalRNNEncoder编码\n",
    "encode_fn = rnn_encoder.UnidirectionalRNNEncoder(encoder_params, mode)\n",
    "encoder_output = encode_fn(encoder_inputs_embedded, encoder_inputs_length)\n",
    "\n",
    "\n",
    "decode_params = beam_search_decoder.BeamSearchDecoder.default_params()\n",
    "decode_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = decoder_hidden_units\n",
    "decode_params\n",
    "\n",
    "from seq2seq.inference import beam_search\n",
    "config = beam_search.BeamSearchConfig(\n",
    "    beam_width = 10,\n",
    "    vocab_size = vocab_size,\n",
    "    eos_token = EOS,\n",
    "    length_penalty_weight = 0.6,\n",
    "    choose_successors_fn = beam_search.choose_top_k)\n",
    "\n",
    "from seq2seq.contrib.seq2seq import helper as decode_helper\n",
    "\n",
    "beam_helper = decode_helper.GreedyEmbeddingHelper(\n",
    "    embedding=output_embeddings,\n",
    "    start_tokens=[0] * config.beam_width,\n",
    "    end_token=-1)\n",
    "\n",
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)\n",
    "\n",
    "\"\"\"\n",
    "decoder_fn = create_decoder(\n",
    "    helper=beam_helper,\n",
    "    mode=tf.contrib.learn.ModeKeys.INFER)\n",
    "\"\"\"\n",
    "decoder_fn = beam_search_decoder.BeamSearchDecoder(\n",
    "    decoder=decoder_fn,\n",
    "    config=config)\n",
    "\n",
    "\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, decoder_inputs)\n",
    "\n",
    "with tf.name_scope('minibatch'):\n",
    "    helper = decode_helper.TrainingHelper(\n",
    "        inputs = decoder_inputs_embedded,\n",
    "        sequence_length = decoder_inputs_length)\n",
    "    \n",
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)\n",
    "\n",
    "decoder_output, decoder_state = decoder_fn(encoder_output.final_state, helper)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32), \n",
    "        logits=tf.transpose(decoder_output.logits, perm = [1, 0, 2]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# 通过阅读decoder_helper的定义，\n",
    "# 输入数据是batch-major\n",
    "# 而输出数据是time-major...\n",
    "# 所以需要对输出的logits做一次transpose\n",
    "# labels: [batch_size, max_length, vocab_size]\n",
    "# logits （tranpose之前）: [max_length, batch_size, vocab_size] \n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits = tf.transpose(decoder_output.logits, perm=[1,0,2]), labels = decoder_targets))\n",
    "\"\"\"\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global idx = 0\n",
    "def next_feed():\n",
    "    if idx+32 >=len(data_qa):\n",
    "        np.random.shuffle(data_qa)\n",
    "        \n",
    "            \n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, decoder_targets_length_ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_,\n",
    "        decoder_targets_length: decoder_targets_length_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/home/dong/Dropbox/Projects/NLP/seq2seq')\n",
    "from seq2seq.encoders import rnn_encoder\n",
    "from seq2seq.decoders import basic_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Working with TF commit 24466c2e6d32621cd85f0a78d47df6eed2c5c5a6\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell, LSTMStateTuple\n",
    "import helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Seq2SeqModel():\n",
    "    \"\"\"Seq2Seq model usign blocks from new `tf.contrib.seq2seq`.\n",
    "    Requires TF 1.0.0-alpha\"\"\"\n",
    "\n",
    "    PAD = 0\n",
    "    EOS = 1\n",
    "\n",
    "    def __init__(self, encoder_cell, decoder_cell, vocab_size, embedding_size,\n",
    "                 bidirectional=True,\n",
    "                 attention=False,\n",
    "                 debug=False):\n",
    "        self.debug = debug\n",
    "        self.bidirectional = bidirectional\n",
    "        self.attention = attention\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.encoder_cell = encoder_cell\n",
    "        self.decoder_cell = decoder_cell\n",
    "\n",
    "        self._make_graph()\n",
    "\n",
    "    @property\n",
    "    def decoder_hidden_units(self):\n",
    "        # @TODO: is this correct for LSTMStateTuple?\n",
    "        return self.decoder_cell.output_size\n",
    "\n",
    "    def _make_graph(self):\n",
    "        if self.debug:\n",
    "            self._init_debug_inputs()\n",
    "        else:\n",
    "            self._init_placeholders()\n",
    "\n",
    "        self._init_decoder_train_connectors()\n",
    "        self._init_embeddings()\n",
    "\n",
    "        if self.bidirectional:\n",
    "            self._init_bidirectional_encoder()\n",
    "        else:\n",
    "            self._init_simple_encoder()\n",
    "\n",
    "        self._init_decoder()\n",
    "\n",
    "        self._init_optimizer()\n",
    "\n",
    "    def _init_debug_inputs(self):\n",
    "        \"\"\" Everything is time-major \"\"\"\n",
    "        x = [[5, 6, 7],\n",
    "             [7, 6, 0],\n",
    "             [0, 7, 0]]\n",
    "        xl = [2, 3, 1]\n",
    "        self.encoder_inputs = tf.constant(x, dtype=tf.int32, name='encoder_inputs')\n",
    "        self.encoder_inputs_length = tf.constant(xl, dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "        self.decoder_targets = tf.constant(x, dtype=tf.int32, name='decoder_targets')\n",
    "        self.decoder_targets_length = tf.constant(xl, dtype=tf.int32, name='decoder_targets_length')\n",
    "\n",
    "    def _init_placeholders(self):\n",
    "        \"\"\" Everything is time-major \"\"\"\n",
    "        self.encoder_inputs = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs',\n",
    "        )\n",
    "        self.encoder_inputs_length = tf.placeholder(\n",
    "            shape=(None,),\n",
    "            dtype=tf.int32,\n",
    "            name='encoder_inputs_length',\n",
    "        )\n",
    "\n",
    "        # required for training, not required for testing\n",
    "        self.decoder_targets = tf.placeholder(\n",
    "            shape=(None, None),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_targets'\n",
    "        )\n",
    "        self.decoder_targets_length = tf.placeholder(\n",
    "            shape=(None,),\n",
    "            dtype=tf.int32,\n",
    "            name='decoder_targets_length',\n",
    "        )\n",
    "\n",
    "    def _init_decoder_train_connectors(self):\n",
    "        \"\"\"\n",
    "        During training, `decoder_targets`\n",
    "        and decoder logits. This means that their shapes should be compatible.\n",
    "\n",
    "        Here we do a bit of plumbing to set this up.\n",
    "        \"\"\"\n",
    "        with tf.name_scope('DecoderTrainFeeds'):\n",
    "            sequence_size, batch_size = tf.unstack(tf.shape(self.decoder_targets))\n",
    "\n",
    "            EOS_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * self.EOS\n",
    "            PAD_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * self.PAD\n",
    "\n",
    "            self.decoder_train_inputs = tf.concat([EOS_SLICE, self.decoder_targets], axis=0)\n",
    "            self.decoder_train_length = self.decoder_targets_length + 1\n",
    "\n",
    "            decoder_train_targets = tf.concat([self.decoder_targets, PAD_SLICE], axis=0)\n",
    "            decoder_train_targets_seq_len, _ = tf.unstack(tf.shape(decoder_train_targets))\n",
    "            decoder_train_targets_eos_mask = tf.one_hot(self.decoder_train_length - 1,\n",
    "                                                        decoder_train_targets_seq_len,\n",
    "                                                        on_value=self.EOS, off_value=self.PAD,\n",
    "                                                        dtype=tf.int32)\n",
    "            decoder_train_targets_eos_mask = tf.transpose(decoder_train_targets_eos_mask, [1, 0])\n",
    "\n",
    "            # hacky way using one_hot to put EOS symbol at the end of target sequence\n",
    "            decoder_train_targets = tf.add(decoder_train_targets,\n",
    "                                           decoder_train_targets_eos_mask)\n",
    "\n",
    "            self.decoder_train_targets = decoder_train_targets\n",
    "\n",
    "            self.loss_weights = tf.ones([\n",
    "                batch_size,\n",
    "                tf.reduce_max(self.decoder_train_length)\n",
    "            ], dtype=tf.float32, name=\"loss_weights\")\n",
    "\n",
    "    def _init_embeddings(self):\n",
    "        with tf.variable_scope(\"embedding\") as scope:\n",
    "\n",
    "            # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "            sqrt3 = math.sqrt(3)\n",
    "            initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "\n",
    "            self.embedding_matrix = tf.get_variable(\n",
    "                name=\"embedding_matrix\",\n",
    "                shape=[self.vocab_size, self.embedding_size],\n",
    "                initializer=initializer,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            self.encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "                self.embedding_matrix, self.encoder_inputs)\n",
    "\n",
    "            self.decoder_train_inputs_embedded = tf.nn.embedding_lookup(\n",
    "                self.embedding_matrix, self.decoder_train_inputs)\n",
    "\n",
    "    def _init_simple_encoder(self):\n",
    "        with tf.variable_scope(\"Encoder\") as scope:\n",
    "            (self.encoder_outputs, self.encoder_state) = (\n",
    "                tf.nn.dynamic_rnn(cell=self.encoder_cell,\n",
    "                                  inputs=self.encoder_inputs_embedded,\n",
    "                                  sequence_length=self.encoder_inputs_length,\n",
    "                                  time_major=True,\n",
    "                                  dtype=tf.float32)\n",
    "                )\n",
    "\n",
    "    def _init_bidirectional_encoder(self):\n",
    "        with tf.variable_scope(\"BidirectionalEncoder\") as scope:\n",
    "\n",
    "            ((encoder_fw_outputs,\n",
    "              encoder_bw_outputs),\n",
    "             (encoder_fw_state,\n",
    "              encoder_bw_state)) = (\n",
    "                tf.nn.bidirectional_dynamic_rnn(cell_fw=self.encoder_cell,\n",
    "                                                cell_bw=self.encoder_cell,\n",
    "                                                inputs=self.encoder_inputs_embedded,\n",
    "                                                sequence_length=self.encoder_inputs_length,\n",
    "                                                time_major=True,\n",
    "                                                dtype=tf.float32)\n",
    "                )\n",
    "\n",
    "            self.encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "            if isinstance(encoder_fw_state, LSTMStateTuple):\n",
    "\n",
    "                encoder_state_c = tf.concat(\n",
    "                    (encoder_fw_state.c, encoder_bw_state.c), 1, name='bidirectional_concat_c')\n",
    "                encoder_state_h = tf.concat(\n",
    "                    (encoder_fw_state.h, encoder_bw_state.h), 1, name='bidirectional_concat_h')\n",
    "                self.encoder_state = LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)\n",
    "\n",
    "            elif isinstance(encoder_fw_state, tf.Tensor):\n",
    "                self.encoder_state = tf.concat((encoder_fw_state, encoder_bw_state), 1, name='bidirectional_concat')\n",
    "\n",
    "    def _init_decoder(self):\n",
    "        with tf.variable_scope(\"Decoder\") as scope:\n",
    "            def output_fn(outputs):\n",
    "                return tf.contrib.layers.linear(outputs, self.vocab_size, scope=scope)\n",
    "\n",
    "            if not self.attention:\n",
    "                decoder_fn_train = seq2seq.simple_decoder_fn_train(encoder_state=self.encoder_state)\n",
    "                decoder_fn_inference = seq2seq.simple_decoder_fn_inference(\n",
    "                    output_fn=output_fn,\n",
    "                    encoder_state=self.encoder_state,\n",
    "                    embeddings=self.embedding_matrix,\n",
    "                    start_of_sequence_id=self.EOS,\n",
    "                    end_of_sequence_id=self.EOS,\n",
    "                    maximum_length=tf.reduce_max(self.encoder_inputs_length) + 3,\n",
    "                    num_decoder_symbols=self.vocab_size,\n",
    "                )\n",
    "            else:\n",
    "\n",
    "                # attention_states: size [batch_size, max_time, num_units]\n",
    "                attention_states = tf.transpose(self.encoder_outputs, [1, 0, 2])\n",
    "\n",
    "                (attention_keys,\n",
    "                attention_values,\n",
    "                attention_score_fn,\n",
    "                attention_construct_fn) = seq2seq.prepare_attention(\n",
    "                    attention_states=attention_states,\n",
    "                    attention_option=\"bahdanau\",\n",
    "                    num_units=self.decoder_hidden_units,\n",
    "                )\n",
    "\n",
    "                decoder_fn_train = seq2seq.attention_decoder_fn_train(\n",
    "                    encoder_state=self.encoder_state,\n",
    "                    attention_keys=attention_keys,\n",
    "                    attention_values=attention_values,\n",
    "                    attention_score_fn=attention_score_fn,\n",
    "                    attention_construct_fn=attention_construct_fn,\n",
    "                    name='attention_decoder'\n",
    "                )\n",
    "\n",
    "                decoder_fn_inference = seq2seq.attention_decoder_fn_inference(\n",
    "                    output_fn=output_fn,\n",
    "                    encoder_state=self.encoder_state,\n",
    "                    attention_keys=attention_keys,\n",
    "                    attention_values=attention_values,\n",
    "                    attention_score_fn=attention_score_fn,\n",
    "                    attention_construct_fn=attention_construct_fn,\n",
    "                    embeddings=self.embedding_matrix,\n",
    "                    start_of_sequence_id=self.EOS,\n",
    "                    end_of_sequence_id=self.EOS,\n",
    "                    maximum_length=tf.reduce_max(self.encoder_inputs_length) + 3,\n",
    "                    num_decoder_symbols=self.vocab_size,\n",
    "                )\n",
    "\n",
    "            (self.decoder_outputs_train,\n",
    "             self.decoder_state_train,\n",
    "             self.decoder_context_state_train) = (\n",
    "                seq2seq.dynamic_rnn_decoder(\n",
    "                    cell=self.decoder_cell,\n",
    "                    decoder_fn=decoder_fn_train,\n",
    "                    inputs=self.decoder_train_inputs_embedded,\n",
    "                    sequence_length=self.decoder_train_length,\n",
    "                    time_major=True,\n",
    "                    scope=scope,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.decoder_logits_train = output_fn(self.decoder_outputs_train)\n",
    "            self.decoder_prediction_train = tf.argmax(self.decoder_logits_train, axis=-1, name='decoder_prediction_train')\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            (self.decoder_logits_inference,\n",
    "             self.decoder_state_inference,\n",
    "             self.decoder_context_state_inference) = (\n",
    "                seq2seq.dynamic_rnn_decoder(\n",
    "                    cell=self.decoder_cell,\n",
    "                    decoder_fn=decoder_fn_inference,\n",
    "                    time_major=True,\n",
    "                    scope=scope,\n",
    "                )\n",
    "            )\n",
    "            self.decoder_prediction_inference = tf.argmax(self.decoder_logits_inference, axis=-1, name='decoder_prediction_inference')\n",
    "\n",
    "    def _init_optimizer(self):\n",
    "        logits = tf.transpose(self.decoder_logits_train, [1, 0, 2])\n",
    "        targets = tf.transpose(self.decoder_train_targets, [1, 0])\n",
    "        self.loss = seq2seq.sequence_loss(logits=logits, targets=targets,\n",
    "                                          weights=self.loss_weights)\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "\n",
    "    def make_train_inputs(self, input_seq, target_seq):\n",
    "        inputs_, inputs_length_ = helpers.batch(input_seq)\n",
    "        targets_, targets_length_ = helpers.batch(target_seq)\n",
    "        return {\n",
    "            self.encoder_inputs: inputs_,\n",
    "            self.encoder_inputs_length: inputs_length_,\n",
    "            self.decoder_targets: targets_,\n",
    "            self.decoder_targets_length: targets_length_,\n",
    "        }\n",
    "\n",
    "    def make_inference_inputs(self, input_seq):\n",
    "        inputs_, inputs_length_ = helpers.batch(input_seq)\n",
    "        return {\n",
    "            self.encoder_inputs: inputs_,\n",
    "            self.encoder_inputs_length: inputs_length_,\n",
    "        }\n",
    "\n",
    "\n",
    "def make_seq2seq_model(**kwargs):\n",
    "    args = dict(encoder_cell=LSTMCell(10),\n",
    "                decoder_cell=LSTMCell(20),\n",
    "                vocab_size=10,\n",
    "                embedding_size=10,\n",
    "                attention=True,\n",
    "                bidirectional=True,\n",
    "                debug=False)\n",
    "    args.update(kwargs)\n",
    "    return Seq2SeqModel(**args)\n",
    "\n",
    "\n",
    "def train_on_copy_task(session, model,\n",
    "                       length_from=3, length_to=8,\n",
    "                       vocab_lower=2, vocab_upper=10,\n",
    "                       batch_size=100,\n",
    "                       max_batches=5000,\n",
    "                       batches_in_epoch=1000,\n",
    "                       verbose=True):\n",
    "\n",
    "    batches = helpers.random_sequences(length_from=length_from, length_to=length_to,\n",
    "                                       vocab_lower=vocab_lower, vocab_upper=vocab_upper,\n",
    "                                       batch_size=batch_size)\n",
    "    loss_track = []\n",
    "    try:\n",
    "        for batch in range(max_batches+1):\n",
    "            batch_data = next(batches)\n",
    "            fd = model.make_train_inputs(batch_data, batch_data)\n",
    "            _, l = session.run([model.train_op, model.loss], fd)\n",
    "            loss_track.append(l)\n",
    "\n",
    "            if verbose:\n",
    "                if batch == 0 or batch % batches_in_epoch == 0:\n",
    "                    print('batch {}'.format(batch))\n",
    "                    print('  minibatch loss: {}'.format(session.run(model.loss, fd)))\n",
    "                    for i, (e_in, dt_pred) in enumerate(zip(\n",
    "                            fd[model.encoder_inputs].T,\n",
    "                            session.run(model.decoder_prediction_train, fd).T\n",
    "                        )):\n",
    "                        print('  sample {}:'.format(i + 1))\n",
    "                        print('    enc input           > {}'.format(e_in))\n",
    "                        print('    dec train predicted > {}'.format(dt_pred))\n",
    "                        if i >= 2:\n",
    "                            break\n",
    "                    print()\n",
    "    except KeyboardInterrupt:\n",
    "        print('training interrupted')\n",
    "\n",
    "    return loss_track\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import sys\n",
    "\n",
    "    if 'fw-debug' in sys.argv:\n",
    "        tf.reset_default_graph()\n",
    "        with tf.Session() as session:\n",
    "            model = make_seq2seq_model(debug=True)\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            session.run(model.decoder_prediction_train)\n",
    "            session.run(model.decoder_prediction_train)\n",
    "\n",
    "    elif 'fw-inf' in sys.argv:\n",
    "        tf.reset_default_graph()\n",
    "        with tf.Session() as session:\n",
    "            model = make_seq2seq_model()\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            fd = model.make_inference_inputs([[5, 4, 6, 7], [6, 6]])\n",
    "            inf_out = session.run(model.decoder_prediction_inference, fd)\n",
    "            print(inf_out)\n",
    "\n",
    "    elif 'train' in sys.argv:\n",
    "        tracks = {}\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            model = make_seq2seq_model(attention=True)\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            loss_track_attention = train_on_copy_task(session, model)\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            model = make_seq2seq_model(attention=False)\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            loss_track_no_attention = train_on_copy_task(session, model)\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.plot(loss_track)\n",
    "        print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))\n",
    "\n",
    "    else:\n",
    "        tf.reset_default_graph()\n",
    "        session = tf.InteractiveSession()\n",
    "        model = make_seq2seq_model(debug=False)\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        fd = model.make_inference_inputs([[5, 4, 6, 7], [6, 6]])\n",
    "\n",
    "        inf_out = session.run(model.decoder_prediction_inference, fd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
