{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演示seq2seq lib中的beam search使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('/home/dong/Dropbox/Projects/NLP/seq2seq')\n",
    "from seq2seq.encoders import rnn_encoder\n",
    "from seq2seq.decoders import (basic_decoder, beam_search_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 产生/demo 合成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生10个长度不一（最短3，最长8）的sequences, 其中前十个是:\n",
      "[7, 6, 3, 7, 9, 5, 2, 7]\n",
      "[2, 7, 7, 6]\n",
      "[4, 4, 6, 9, 4, 9]\n",
      "[9, 9, 3, 3, 4, 7]\n",
      "[8, 2, 5, 5, 7, 2, 5]\n",
      "[6, 3, 4]\n",
      "[8, 6, 2, 2]\n",
      "[3, 5, 6, 8, 9, 8]\n",
      "[3, 2, 5, 3, 9]\n",
      "[6, 8, 4]\n"
     ]
    }
   ],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 16\n",
    "\n",
    "encoder_hidden_units = 32\n",
    "decoder_hidden_units = encoder_hidden_units\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 10\n",
    "\n",
    "# 一个generator，每次产生一个minibatch的随机样本\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('产生%d个长度不一（最短3，最长8）的sequences, 其中前十个是:' % batch_size)\n",
    "for seq in next(batches)[:min(batch_size, 10)]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义使用beamsearch decoder的seq2seq模型\n",
    "\n",
    "### 声明placholder和定义encoder部分，同part2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating UnidirectionalRNNEncoder in mode=train\n",
      "INFO:tensorflow:\n",
      "UnidirectionalRNNEncoder:\n",
      "  init_scale: 0.04\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN\n",
    "\n",
    "with tf.name_scope('minibatch'):\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "\n",
    "    decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')\n",
    "    decoder_targets_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_targets_length')\n",
    "    \n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    decoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')\n",
    "\n",
    "    decoder_initial_state = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.float32,\n",
    "                                    name='decoder_initial_state')\n",
    "    \n",
    "\n",
    "# 2-a. 定义encoder\n",
    "encoder_params = rnn_encoder.UnidirectionalRNNEncoder.default_params()\n",
    "encoder_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = encoder_hidden_units\n",
    "encoder_params[\"rnn_cell\"][\"cell_class\"] = \"BasicLSTMCell\"\n",
    "encoder_params  \n",
    "\n",
    "# 2-b. 定义encoding过程\n",
    "# 输入数据转化为embedding格式\n",
    "with tf.name_scope('embedding'):\n",
    "    input_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "    output_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, encoder_inputs)\n",
    "\n",
    "# 使用UnidirectionalRNNEncoder编码\n",
    "encode_fn = rnn_encoder.UnidirectionalRNNEncoder(encoder_params, mode)\n",
    "encoder_output = encode_fn(encoder_inputs_embedded, encoder_inputs_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义decoding模型，使用seq2seq.decoders.beam_search_decoder.BeamSearchDecoder\n",
    "1. input embedding\n",
    "2. helper <-- decoder_input, decoder_input_length\n",
    "3. basic_decoder.BasicDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config decoder的选项，任何基于RNN的decoding操作都需要设定的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_scale': 0.04,\n",
       " 'max_decode_length': 100,\n",
       " 'rnn_cell': {'cell_class': 'BasicLSTMCell',\n",
       "  'cell_params': {'num_units': 32},\n",
       "  'dropout_input_keep_prob': 1.0,\n",
       "  'dropout_output_keep_prob': 1.0,\n",
       "  'num_layers': 1,\n",
       "  'residual_combiner': 'add',\n",
       "  'residual_connections': False,\n",
       "  'residual_dense': False}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_params = beam_search_decoder.BeamSearchDecoder.default_params()\n",
    "decode_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = decoder_hidden_units\n",
    "decode_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config beam_search的选项，即beam_search操作的超参数\n",
    "\n",
    "* beam_width\n",
    "* length_penalty_weight\n",
    "* choose_successors_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamSearchConfig(beam_width=10, vocab_size=10, eos_token=1, length_penalty_weight=0.6, choose_successors_fn=<function choose_top_k at 0x7fe6bea4a6a8>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seq2seq.inference import beam_search\n",
    "config = beam_search.BeamSearchConfig(\n",
    "    beam_width = 10,\n",
    "    vocab_size = vocab_size,\n",
    "    eos_token = EOS,\n",
    "    length_penalty_weight = 0.6,\n",
    "    choose_successors_fn = beam_search.choose_top_k)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq.contrib.seq2seq import helper as decode_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n",
      "INFO:tensorflow:Creating BeamSearchDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BeamSearchDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beam_helper = decode_helper.GreedyEmbeddingHelper(\n",
    "    embedding=output_embeddings,\n",
    "    start_tokens=[0] * config.beam_width,\n",
    "    end_token=-1)\n",
    "\n",
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)\n",
    "\n",
    "\"\"\"\n",
    "decoder_fn = create_decoder(\n",
    "    helper=beam_helper,\n",
    "    mode=tf.contrib.learn.ModeKeys.INFER)\n",
    "\"\"\"\n",
    "decoder_fn = beam_search_decoder.BeamSearchDecoder(\n",
    "    decoder=decoder_fn,\n",
    "    config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch'):\n",
    "    helper = decode_helper.TrainingHelper(\n",
    "        inputs = decoder_inputs_embedded,\n",
    "        sequence_length = decoder_inputs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_state = decoder_fn(encoder_output.final_state, helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32), \n",
    "        logits=tf.transpose(decoder_output.logits, perm = [1, 0, 2]))\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# 通过阅读decoder_helper的定义，\n",
    "# 输入数据是batch-major\n",
    "# 而输出数据是time-major...\n",
    "# 所以需要对输出的logits做一次transpose\n",
    "# labels: [batch_size, max_length, vocab_size]\n",
    "# logits （tranpose之前）: [max_length, batch_size, vocab_size] \n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits = tf.transpose(decoder_output.logits, perm=[1,0,2]), labels = decoder_targets))\n",
    "\"\"\"\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, decoder_targets_length_ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_,\n",
    "        decoder_targets_length: decoder_targets_length_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'minibatch/encoder_inputs:0' shape=(?, ?) dtype=int32>: array([[4, 3, 3, 0, 0, 0, 0, 0],\n",
       "        [8, 8, 2, 5, 6, 4, 3, 0],\n",
       "        [7, 2, 7, 5, 4, 5, 9, 0],\n",
       "        [4, 9, 8, 0, 0, 0, 0, 0],\n",
       "        [6, 5, 3, 6, 5, 8, 2, 6],\n",
       "        [3, 9, 7, 4, 3, 0, 0, 0],\n",
       "        [7, 6, 7, 3, 4, 9, 5, 2],\n",
       "        [3, 3, 8, 9, 7, 0, 0, 0],\n",
       "        [2, 3, 4, 2, 5, 7, 0, 0],\n",
       "        [3, 5, 7, 4, 0, 0, 0, 0]], dtype=int32),\n",
       " <tf.Tensor 'minibatch/decoder_inputs:0' shape=(?, ?) dtype=int32>: array([[1, 4, 3, 3, 0, 0, 0, 0, 0],\n",
       "        [1, 8, 8, 2, 5, 6, 4, 3, 0],\n",
       "        [1, 7, 2, 7, 5, 4, 5, 9, 0],\n",
       "        [1, 4, 9, 8, 0, 0, 0, 0, 0],\n",
       "        [1, 6, 5, 3, 6, 5, 8, 2, 6],\n",
       "        [1, 3, 9, 7, 4, 3, 0, 0, 0],\n",
       "        [1, 7, 6, 7, 3, 4, 9, 5, 2],\n",
       "        [1, 3, 3, 8, 9, 7, 0, 0, 0],\n",
       "        [1, 2, 3, 4, 2, 5, 7, 0, 0],\n",
       "        [1, 3, 5, 7, 4, 0, 0, 0, 0]], dtype=int32),\n",
       " <tf.Tensor 'minibatch/decoder_targets:0' shape=(?, ?) dtype=int32>: array([[4, 3, 3, 1, 0, 0, 0, 0, 0],\n",
       "        [8, 8, 2, 5, 6, 4, 3, 1, 0],\n",
       "        [7, 2, 7, 5, 4, 5, 9, 1, 0],\n",
       "        [4, 9, 8, 1, 0, 0, 0, 0, 0],\n",
       "        [6, 5, 3, 6, 5, 8, 2, 6, 1],\n",
       "        [3, 9, 7, 4, 3, 1, 0, 0, 0],\n",
       "        [7, 6, 7, 3, 4, 9, 5, 2, 1],\n",
       "        [3, 3, 8, 9, 7, 1, 0, 0, 0],\n",
       "        [2, 3, 4, 2, 5, 7, 1, 0, 0],\n",
       "        [3, 5, 7, 4, 1, 0, 0, 0, 0]], dtype=int32),\n",
       " <tf.Tensor 'minibatch/encoder_inputs_length:0' shape=(?,) dtype=int32>: [3,\n",
       "  7,\n",
       "  7,\n",
       "  3,\n",
       "  8,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  6,\n",
       "  4],\n",
       " <tf.Tensor 'minibatch/decoder_inputs_length:0' shape=(?,) dtype=int32>: [4,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  6,\n",
       "  7,\n",
       "  5],\n",
       " <tf.Tensor 'minibatch/decoder_targets_length:0' shape=(?,) dtype=int32>: [4,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  6,\n",
       "  7,\n",
       "  5]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd= next_feed()\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[encoder_inputs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[decoder_inputs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[decoder_targets].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 我们已经定义了一个计算图\n",
    "* 图的输入端是encoder_inputs 和 encoder_inputs_length\n",
    "* 图的输出端是encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[encoder_out1, decoder_out1] = sess.run(\n",
    "    [encoder_output, decoder_output], fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out1.outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 10, 32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.cell_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 10, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.predicted_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder output information:\n",
      "(10, 8, 32)\n",
      "(10, 32)\n",
      "(10, 32)\n"
     ]
    }
   ],
   "source": [
    "print('encoder output information:')\n",
    "print(encoder_out1.outputs.shape)\n",
    "print(encoder_out1.final_state.c.shape)\n",
    "print(encoder_out1.final_state.h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder output information:\n",
      "(9, 10)\n"
     ]
    }
   ],
   "source": [
    "print('decoder output information:')\n",
    "print(decoder_out1.predicted_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out1.predicted_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs:\n",
      "[6 2 3 0 0 0 0]\n",
      "decoder_inputs:\n",
      "[1 6 2 3 0 0 0 0]\n",
      "decoder_targets:\n",
      "[6 2 3 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "x = next_feed()\n",
    "print('encoder_inputs:')\n",
    "print(x[encoder_inputs][0,:])\n",
    "print('decoder_inputs:')\n",
    "print(x[decoder_inputs][0,:])\n",
    "print('decoder_targets:')\n",
    "print(x[decoder_targets][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生100个长度不一的sequence\n",
      "其中前十个是:\n",
      "[2, 3, 9, 7, 2, 4, 5, 8]\n",
      "[4, 6, 6, 8, 4]\n",
      "[8, 9, 7, 5, 9, 6]\n",
      "[3, 8, 5, 2, 5, 5, 3]\n",
      "[6, 7, 7, 9, 7, 9]\n",
      "[3, 4, 7, 8, 8, 3]\n",
      "[7, 7, 8, 7]\n",
      "[8, 3, 3]\n",
      "[3, 8, 8, 9, 4, 4, 7]\n",
      "[9, 6, 4, 3, 5, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    \n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "    decoder_targets_, _ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in batch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in batch]\n",
    "    )\n",
    "    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_\n",
    "    }\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                        vocab_lower=2, vocab_upper=10,\n",
    "                                        batch_size=batch_size)\n",
    "\n",
    "print('产生100个长度不一的sequence')\n",
    "print('其中前十个是:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.307177782058716\n",
      "  sample 1:\n",
      "    input     > [2 4 4 9 0 0 0 0]\n",
      "    predicted > [2 7 7 7 9 7 7 3 3]\n",
      "  sample 2:\n",
      "    input     > [6 8 8 6 0 0 0 0]\n",
      "    predicted > [9 2 6 3 6 6 3 3 3]\n",
      "  sample 3:\n",
      "    input     > [6 6 6 8 4 0 0 0]\n",
      "    predicted > [9 1 7 7 7 7 7 7 7]\n",
      "\n",
      "batch 100\n",
      "  minibatch loss: 1.3989800214767456\n",
      "  sample 1:\n",
      "    input     > [8 2 9 9 0 0 0 0]\n",
      "    predicted > [9 9 9 1 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 4 2 2 0 0 0 0]\n",
      "    predicted > [3 2 2 1 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 2 2 2 3 8 3 3]\n",
      "    predicted > [5 5 5 5 8 8 2 1 1]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 0.9361319541931152\n",
      "  sample 1:\n",
      "    input     > [7 5 8 2 4 5 9 7]\n",
      "    predicted > [5 5 5 5 5 5 7 1 1]\n",
      "  sample 2:\n",
      "    input     > [9 4 4 2 7 3 0 0]\n",
      "    predicted > [4 4 4 2 7 4 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 8 2 2 9 7 0]\n",
      "    predicted > [2 2 2 2 2 2 1 1 0]\n",
      "\n",
      "batch 300\n",
      "  minibatch loss: 0.6657155752182007\n",
      "  sample 1:\n",
      "    input     > [6 5 8 0 0 0 0 0]\n",
      "    predicted > [8 5 8 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [6 8 8 8 5 0 0 0]\n",
      "    predicted > [8 8 8 8 5 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 5 8 2 3 0 0 0]\n",
      "    predicted > [3 5 8 3 3 1 0 0 0]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 0.4867863059043884\n",
      "  sample 1:\n",
      "    input     > [6 7 7 3 9 5 9 0]\n",
      "    predicted > [6 7 3 9 9 5 9 1 0]\n",
      "  sample 2:\n",
      "    input     > [7 5 6 5 4 0 0 0]\n",
      "    predicted > [5 5 6 5 4 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 4 4 9 0 0 0 0]\n",
      "    predicted > [4 4 4 9 1 0 0 0 0]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 0.39313459396362305\n",
      "  sample 1:\n",
      "    input     > [5 6 8 9 9 4 3 0]\n",
      "    predicted > [5 6 9 9 9 4 3 1 0]\n",
      "  sample 2:\n",
      "    input     > [6 2 2 7 6 9 7 5]\n",
      "    predicted > [6 2 7 7 6 7 5 5 1]\n",
      "  sample 3:\n",
      "    input     > [9 3 3 8 6 0 0 0]\n",
      "    predicted > [9 3 3 8 6 1 0 0 0]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 0.324664443731308\n",
      "  sample 1:\n",
      "    input     > [4 5 8 8 9 4 0 0]\n",
      "    predicted > [4 5 8 8 9 4 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 6 5 3 8 0 0 0]\n",
      "    predicted > [6 6 5 3 8 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 4 3 7 4 8 0 0]\n",
      "    predicted > [9 4 3 4 4 8 1 0 0]\n",
      "\n",
      "batch 700\n",
      "  minibatch loss: 0.2500649094581604\n",
      "  sample 1:\n",
      "    input     > [3 8 2 2 6 2 7 6]\n",
      "    predicted > [3 2 2 2 6 7 6 6 1]\n",
      "  sample 2:\n",
      "    input     > [8 3 8 9 4 2 0 0]\n",
      "    predicted > [8 3 8 2 4 2 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 3 7 0 0 0 0 0]\n",
      "    predicted > [8 3 7 1 0 0 0 0 0]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 0.21931880712509155\n",
      "  sample 1:\n",
      "    input     > [7 9 4 6 8 5 5 0]\n",
      "    predicted > [7 9 4 6 5 5 5 1 0]\n",
      "  sample 2:\n",
      "    input     > [5 9 5 6 0 0 0 0]\n",
      "    predicted > [5 9 5 6 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 8 3 3 9 7 6 5]\n",
      "    predicted > [7 8 3 3 7 6 6 5 1]\n",
      "\n",
      "batch 900\n",
      "  minibatch loss: 0.22432130575180054\n",
      "  sample 1:\n",
      "    input     > [8 9 9 0 0 0 0 0]\n",
      "    predicted > [9 9 9 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 6 8 7 6 9 9 0]\n",
      "    predicted > [4 6 8 7 9 9 9 1 0]\n",
      "  sample 3:\n",
      "    input     > [3 7 8 4 9 3 7 4]\n",
      "    predicted > [3 7 8 4 9 3 7 4 1]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.17927610874176025\n",
      "  sample 1:\n",
      "    input     > [5 8 9 0 0 0 0 0]\n",
      "    predicted > [5 8 9 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 9 3 7 7 2 5 0]\n",
      "    predicted > [2 9 7 7 2 2 5 1 0]\n",
      "  sample 3:\n",
      "    input     > [5 4 9 0 0 0 0 0]\n",
      "    predicted > [5 4 9 1 0 0 0 0 0]\n",
      "\n",
      "batch 1100\n",
      "  minibatch loss: 0.15904860198497772\n",
      "  sample 1:\n",
      "    input     > [7 7 8 9 3 0 0 0]\n",
      "    predicted > [7 7 8 9 3 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 8 6 9 0 0 0 0]\n",
      "    predicted > [5 8 6 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 4 9 4 0 0 0 0]\n",
      "    predicted > [5 4 9 4 1 0 0 0 0]\n",
      "\n",
      "batch 1200\n",
      "  minibatch loss: 0.14736728370189667\n",
      "  sample 1:\n",
      "    input     > [3 3 6 5 2 3 5 3]\n",
      "    predicted > [3 3 6 5 2 3 5 3 1]\n",
      "  sample 2:\n",
      "    input     > [9 5 2 8 0 0 0 0]\n",
      "    predicted > [9 5 2 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 3 2 4 0 0 0 0]\n",
      "    predicted > [5 3 2 4 1 0 0 0 0]\n",
      "\n",
      "batch 1300\n",
      "  minibatch loss: 0.11126694828271866\n",
      "  sample 1:\n",
      "    input     > [6 3 4 3 4 2 2 0]\n",
      "    predicted > [6 3 4 3 2 2 2 1 0]\n",
      "  sample 2:\n",
      "    input     > [5 5 2 9 6 0 0 0]\n",
      "    predicted > [5 5 2 9 6 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 6 7 9 8 4 0 0]\n",
      "    predicted > [3 6 7 9 8 4 1 0 0]\n",
      "\n",
      "batch 1400\n",
      "  minibatch loss: 0.1067885309457779\n",
      "  sample 1:\n",
      "    input     > [7 2 9 7 3 8 5 0]\n",
      "    predicted > [7 2 9 7 5 8 5 1 0]\n",
      "  sample 2:\n",
      "    input     > [8 8 7 2 2 6 0 0]\n",
      "    predicted > [8 8 7 2 2 6 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 9 8 3 6 2 3 0]\n",
      "    predicted > [6 9 8 3 6 2 3 1 0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 0.14241264760494232\n",
      "  sample 1:\n",
      "    input     > [6 6 5 8 9 0 0 0]\n",
      "    predicted > [6 6 5 8 9 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 3 3 9 0 0 0 0]\n",
      "    predicted > [8 3 3 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [2 9 9 6 0 0 0 0]\n",
      "    predicted > [2 9 9 6 1 0 0 0 0]\n",
      "\n",
      "batch 1600\n",
      "  minibatch loss: 0.08519871532917023\n",
      "  sample 1:\n",
      "    input     > [3 6 8 7 7 5 8 0]\n",
      "    predicted > [3 6 8 7 7 5 8 1 0]\n",
      "  sample 2:\n",
      "    input     > [9 4 5 9 2 3 2 0]\n",
      "    predicted > [9 4 9 9 2 3 2 1 0]\n",
      "  sample 3:\n",
      "    input     > [7 2 4 3 5 6 0 0]\n",
      "    predicted > [7 2 4 3 5 6 1 0 0]\n",
      "\n",
      "batch 1700\n",
      "  minibatch loss: 0.09281522035598755\n",
      "  sample 1:\n",
      "    input     > [5 2 2 2 8 5 4 0]\n",
      "    predicted > [2 2 2 2 8 5 8 1 0]\n",
      "  sample 2:\n",
      "    input     > [2 6 7 4 8 9 7 0]\n",
      "    predicted > [2 6 7 4 8 9 7 1 0]\n",
      "  sample 3:\n",
      "    input     > [2 3 4 5 4 5 7 0]\n",
      "    predicted > [2 3 4 5 4 5 7 1 0]\n",
      "\n",
      "batch 1800\n",
      "  minibatch loss: 0.09957244992256165\n",
      "  sample 1:\n",
      "    input     > [6 8 9 8 0 0 0 0]\n",
      "    predicted > [6 8 9 8 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 3 2 6 5 5 8 7]\n",
      "    predicted > [4 3 2 6 5 5 8 7 1]\n",
      "  sample 3:\n",
      "    input     > [8 3 3 6 6 7 0 0]\n",
      "    predicted > [8 3 3 6 6 7 1 0 0]\n",
      "\n",
      "batch 1900\n",
      "  minibatch loss: 0.10420332103967667\n",
      "  sample 1:\n",
      "    input     > [4 6 8 0 0 0 0 0]\n",
      "    predicted > [4 6 8 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 8 2 7 4 5 4 0]\n",
      "    predicted > [2 8 2 7 4 5 4 1 0]\n",
      "  sample 3:\n",
      "    input     > [4 4 6 7 0 0 0 0]\n",
      "    predicted > [4 4 6 7 1 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.07217496633529663\n",
      "  sample 1:\n",
      "    input     > [3 6 6 3 9 6 5 4]\n",
      "    predicted > [3 6 6 3 9 6 5 7 1]\n",
      "  sample 2:\n",
      "    input     > [2 8 6 4 7 2 5 0]\n",
      "    predicted > [2 8 6 4 7 2 5 1 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 6 9 6 2 2 3]\n",
      "    predicted > [4 2 6 9 6 2 2 3 1]\n",
      "\n",
      "batch 2100\n",
      "  minibatch loss: 0.05769014731049538\n",
      "  sample 1:\n",
      "    input     > [5 8 7 0 0 0 0 0]\n",
      "    predicted > [5 8 7 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 5 6 8 0 0 0 0]\n",
      "    predicted > [4 5 6 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [9 8 2 0 0 0 0 0]\n",
      "    predicted > [9 8 2 1 0 0 0 0 0]\n",
      "\n",
      "batch 2200\n",
      "  minibatch loss: 0.06712320446968079\n",
      "  sample 1:\n",
      "    input     > [5 2 5 0 0 0 0 0]\n",
      "    predicted > [5 2 5 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [3 9 8 3 5 2 2 0]\n",
      "    predicted > [3 9 8 3 2 2 2 1 0]\n",
      "  sample 3:\n",
      "    input     > [4 7 9 0 0 0 0 0]\n",
      "    predicted > [4 7 9 1 0 0 0 0 0]\n",
      "\n",
      "batch 2300\n",
      "  minibatch loss: 0.060568150132894516\n",
      "  sample 1:\n",
      "    input     > [3 6 5 7 3 0 0 0]\n",
      "    predicted > [3 6 5 7 3 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 8 7 8 0 0 0 0]\n",
      "    predicted > [7 8 7 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 5 7 7 3 5 3 0]\n",
      "    predicted > [3 5 7 7 3 5 3 1 0]\n",
      "\n",
      "batch 2400\n",
      "  minibatch loss: 0.058682627975940704\n",
      "  sample 1:\n",
      "    input     > [5 5 5 5 6 0 0 0]\n",
      "    predicted > [5 5 5 5 6 1 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 3 3 4 8 4 0 0]\n",
      "    predicted > [2 3 3 4 8 4 1 0 0]\n",
      "  sample 3:\n",
      "    input     > [7 9 6 6 4 9 0 0]\n",
      "    predicted > [7 9 6 6 4 9 1 0 0]\n",
      "\n",
      "batch 2500\n",
      "  minibatch loss: 0.07027692347764969\n",
      "  sample 1:\n",
      "    input     > [8 9 4 2 6 4 3 6]\n",
      "    predicted > [8 9 4 2 6 4 3 6 1]\n",
      "  sample 2:\n",
      "    input     > [6 8 4 9 0 0 0 0]\n",
      "    predicted > [6 8 4 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [6 9 4 9 2 0 0 0]\n",
      "    predicted > [6 9 4 9 2 1 0 0 0]\n",
      "\n",
      "batch 2600\n",
      "  minibatch loss: 0.05428970977663994\n",
      "  sample 1:\n",
      "    input     > [2 4 3 6 0 0 0 0]\n",
      "    predicted > [2 4 3 6 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 6 5 7 4 0 0 0]\n",
      "    predicted > [2 6 5 7 4 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 5 4 0 0 0 0 0]\n",
      "    predicted > [8 5 4 1 0 0 0 0 0]\n",
      "\n",
      "batch 2700\n",
      "  minibatch loss: 0.03605054318904877\n",
      "  sample 1:\n",
      "    input     > [3 7 6 9 7 4 0 0]\n",
      "    predicted > [3 7 6 9 7 4 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [7 4 4 9 4 0 0 0]\n",
      "    predicted > [4 4 4 9 4 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 7 8 7 4 6 5 0]\n",
      "    predicted > [4 7 8 7 4 6 5 1 0]\n",
      "\n",
      "batch 2800\n",
      "  minibatch loss: 0.04831724613904953\n",
      "  sample 1:\n",
      "    input     > [8 3 3 8 4 7 0 0]\n",
      "    predicted > [8 3 3 8 4 7 1 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 2 8 6 3 0 0 0]\n",
      "    predicted > [5 2 8 6 3 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 9 5 6 8 2 5 3]\n",
      "    predicted > [3 9 5 6 8 2 5 3 1]\n",
      "\n",
      "batch 2900\n",
      "  minibatch loss: 0.05388916656374931\n",
      "  sample 1:\n",
      "    input     > [7 5 3 3 4 9 8 0]\n",
      "    predicted > [7 5 3 3 4 9 8 1 0]\n",
      "  sample 2:\n",
      "    input     > [7 4 5 0 0 0 0 0]\n",
      "    predicted > [7 4 5 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [4 2 9 6 3 8 5 0]\n",
      "    predicted > [4 2 9 6 3 8 5 1 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.07778044044971466\n",
      "  sample 1:\n",
      "    input     > [3 6 8 2 0 0 0 0]\n",
      "    predicted > [3 6 8 2 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [5 5 6 8 5 7 7 0]\n",
      "    predicted > [5 5 6 8 5 7 7 1 0]\n",
      "  sample 3:\n",
      "    input     > [5 8 5 4 0 0 0 0]\n",
      "    predicted > [5 8 5 4 1 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 100\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_output.predicted_ids, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs], predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.0679 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VOXd//H3l6xA2BPCTsImoohKirjjhqj0sdUu2J9L\nVyvYWq1PW9TH9WnV1qe2dS9W22qt1rZqtWBFXJFFDDuyBggEhBCIkI3s9++PGUL2TMIkZ+bk87qu\nXJ45556Z780xn5y5z5n7mHMOERHxly5eFyAiIuGncBcR8SGFu4iIDyncRUR8SOEuIuJDCncRER9S\nuIuI+JDCXUTEhxTuIiI+FOvVGycnJ7u0tDSv3l5EJCotX758v3MupaV2noV7WloamZmZXr29iEhU\nMrMdobTTsIyIiA8p3EVEfEjhLiLiQwp3EREfUriLiPiQwl1ExIcU7iIiPhR14b5pbyEPvrmRwtIK\nr0sREYlYURfuO/NLeOqDrWTtK/K6FBGRiBV14T6qfxKAwl1EpBlRF+5D+3QlPqYLWXkKdxGRpkRd\nuMfGdCEtuRtbdeQuItKkqAt3CAzNbM0r9roMEZGIFZXhnp7cnZ35JVRVO69LERGJSFEZ7qk9E6mq\ndhwoLvO6FBGRiBSV4d6/RwIAeYUKdxGRxkRluKf0SARgn8JdRKRRURnuA3oFwn1XfonHlYiIRKao\nDPdBvRIZ0DORZdmfe12KiEhEispwNzPSk7vz6e5DXpciIhKRojLcAWK6GNv2F+OcLocUEakvasP9\nyBwzutZdRKShqA331J6Bk6oVVQp3EZH6ojbcX/pkJwCLsvZ7XImISOSJ2nDfcSBwGeTug4c9rkRE\nJPJEbbj/bsbJAIwOjr2LiMhRURvuA4Jj7gs1LCMi0kDUhvuJg3sBcLi8yuNKREQiT9SGe/eEWPp1\nj6e8qtrrUkREIk7UhjvAgeJyFmtYRkSkgagOd4DsA5o8TESkvqgPdxERaajFcDezoWb2npmtN7NP\nzexHjbQxM3vEzLLMbI2Zndo+5YqISChiQ2hTCdzqnFthZj2A5Wb2tnNufa02lwCjgz+nAU8G/ysi\nIh5o8cjdObfHObciuFwIbAAG12t2OfCcC1gK9DazgWGvVkREQtKqMXczSwNOAT6ut2kwkFPr8S4a\n/gHAzK43s0wzy8zLy2tdpY349pnpJCWE8uFDRKRzCTnczSwJ+Cdws3OuoC1v5pyb45zLcM5lpKSk\ntOUl6oiLMYrKKo/5dURE/CakcDezOALB/oJz7pVGmuwGhtZ6PCS4rl39c8UuAPYVlrb3W4mIRJVQ\nrpYx4Blgg3Pu4SaavQ5cG7xqZjJwyDm3J4x1Nuq609MAKCzV0buISG2hDFifCVwDrDWzVcF1twPD\nAJxzTwHzgEuBLKAE+Fb4S21ozIAegOaXERGpr8Vwd859BFgLbRxwY7iKClVFcF6ZPy/O5qGvTujo\ntxcRiVhR/Q3VvYcCY+1/X77L40pERCJLVIf7uEE9AZgwpJfHlYiIRJaoDveThvQGYPpJgzyuREQk\nskR1uMdY4FRAZbXzuBIRkcgS3eHeJRDu1U7hLiJSmy/C/aG3NnlciYhIZInqcO/S7AWaIiKdV1SH\nu9nRdC+t0BeZRESOiOpwr+2J97d6XYKISMTwTbgXllZ4XYKISMTwTbjHmAbgRUSO8E24a153EZGj\nfBPuL32S03IjEZFOwjfhLiIiRyncRUR8KOrDvUdiYEr6AT0TPa5ERCRyRH24VwcnDdtbUMp9b6z3\nuBoRkcgQ9eH+6DdOqVl+dtF2DysREYkcUR/u549N9boEEZGIE/XhLiIiDSncRUR8SOEuIuJDvgr3\n1J4JXpcgIhIRfBXuuQVlHCwp97oMERHP+SrcAe54bZ3XJYiIeM534X6oRPO6i4j4ItxrTz1QUVXt\nYSUiIpHBF+E+96azapZLKxXuIiK+CPd+SUevklmdc9DDSkREIoMvwl1EROpSuIuI+JAvw90553UJ\nIiKe8k24//uHR0+qFpdXeViJiIj3fBPuJw7uVbM88y/L2XPosIfViIh4q8VwN7NnzWyfmTX61U8z\nm2Jmh8xsVfDnrvCX2ToLt+zn5pdWeV2GiIhnYkNo8yfgMeC5ZtosdM5ND0tFYVJcXul1CSIinmnx\nyN059yGQ3wG1hNW63QVelyAi4plwjbmfYWZrzOxNMzshTK/Zaq/OOsOrtxYRiSjhCPcVwDDn3EnA\no8BrTTU0s+vNLNPMMvPy8sLw1nWdMqxPncdvrt0T9vcQEYkGxxzuzrkC51xRcHkeEGdmyU20neOc\ny3DOZaSkpBzrW7do5gsr2v09REQi0TGHu5kNMDMLLk8KvuaBY31dERFpuxavljGzF4EpQLKZ7QLu\nBuIAnHNPAV8BZppZJXAYmOH0FVEREU+1GO7Ouata2P4YgUslI8J3z0rnDx9t97oMERFP+eYbqkcM\n7N21zuPXV3/mUSUiIt7xXbh3jYup8/imF1d6VImIiHd8F+5fzRjidQkiIp7zXbjHxfiuSyIiraYk\nFBHxIYW7iIgP+TLcA1+pEhHpvHwZ7ot+dr7XJYiIeMqX4T6o3rXui7L2e1SJiIg3fBnu9b24bKfX\nJYiIdCjfhvvUcak1y+WV1R5WIiLS8Xwb7icMOnrD7Pnrcz2sRESk4/k23L99Vlqdx0VluqeqiHQe\nvg33HolxdR5rFmIR6Ux8G+71KdpFpDPpNOF+uLzK6xJERDqMr8P9jR+cVbN82v3veFiJiEjH8nW4\nj+zfvc7jyipdEikinYOvwz2mS91JZmbMWUpVtUbfRcT/fB3usV3qdi9zx+f8eXG2N8WIiHQgX4d7\nl0Zmh7zv3+t19C4ivufrcLcm5v7dvr+ogysREelYvg73pmzOVbiLiL/5PtyX3NZwbvdZL6zwoBIR\nkY7j+3Af2KsrKT0SvC5DRKRD+T7cAWZNGel1CSIiHapThPu3zkznwuNTW24oIuITnSLcAX555fg6\nj/cVlnpUiYhI++s04d6za90pgBes3+dRJSIi7a/ThHtcTN2u3v7qWs3xLiK+1WnCvTFf//1Sr0sQ\nEWkXnTrcl2XnU1Ku2++JiP906nAXEfGrThXujV0O+e7GfazbfciDakRE2k+L4W5mz5rZPjNb18R2\nM7NHzCzLzNaY2anhLzM8RqcmNVj3g7+uZPqjH1FWqdvwiYh/hHLk/idgWjPbLwFGB3+uB5489rLa\nx80XjubuL47jC2l9Gmz79p8+8aAiEZH20WK4O+c+BPKbaXI58JwLWAr0NrOB4SownBJiY/jWmelM\nGNK7wbZFWQc8qEhEpH2EY8x9MJBT6/Gu4LqIVambdYiIz3XoCVUzu97MMs0sMy8vryPfuo7jBvTw\n7L1FRDpCOMJ9NzC01uMhwXUNOOfmOOcynHMZKSkpYXjrtpnxhaGNrv94m4ZmRMQfwhHurwPXBq+a\nmQwccs7tCcPrtpumbr/37ibNNyMi/hDKpZAvAkuA48xsl5l9x8xuMLMbgk3mAduALOBpYFa7VRtG\n7956boN1RuOhLyISbWJbauCcu6qF7Q64MWwVdZARKQ2veW/igF5EJOp0qm+otuTJ97dyuFxfZhKR\n6Nepw/2VWWc0WHfGg+94UImISHh16nA/dVgffnLxcXXWfV5S4VE1IiLh06nDHeDG80Zx1aTGL40U\nEYlWnT7cAb4ysW64V+sbrCIS5RTuwIQhveo8fuaj7WzNK/KoGhGRY6dwB2Lr3V/1F/M2cMGvP6Ci\nqtqjikREjo3CvRmb9hZ6XYKISJso3IP+ObPhZZHTH/2IojLdY1VEoo/CPWji8D6cPTq5wfq/Z+Y0\n0lpEJLIp3Gt5/junNVh37xvrPahEROTYKNzruePS4xusW51z0INKRETaTuFez1WnDWuw7vLHF3lQ\niYhI2ync60lKiKV7fIzXZYiIHBOFeyPSU7o3WFdYqjlnRCR6KNwb8fWMhnPNfP/55R5UIiLSNgr3\nRlw9eXiDdYu3HtBlkSISNRTujWjqHqs/+ccarnhCJ1dFJPIp3Jvw7x+e1ej6FTt1WaSIRD6FexNO\nHNyLy8YPbHTb8h35HVyNiEjrKNyb0dQNs698cknHFiIi0koK92bc/cUTiI9t/J/o9lfXdnA1IiKh\nU7g3I6VHAu/8+NxGt/31450dXI2ISOgU7i0Y2rdbk9u27y/uwEpEREKncA/BnGsmNrr+vP97v2ML\nEREJkcI9BFNPGMCY1KRGt/1l6Q7dUFtEIo7CPURdmrh05n9eW8czH23v4GpERJqncA+DX8zbwMa9\nBV6XISJSQ+EeovPG9m92+7TfLmT3wcMdVI2ISPMU7iH676nHsXj2+c22KSrVzbRFJDIo3EMU08UY\n1Ltrs22+pDs2iUiEULi30u2Xjm1y2+GKKs7/v/fZeaCE0oqqDqxKRKSuWK8LiDbXnzOSAb26cvao\nZMzgwoc/ZH9RWc32bfuLOeeh90hP7s57/z3Fu0JFpFPTkXsb/NeEQfTpHk/vbvFcNK7xE63b9xdz\noKiM55fuoLyyuoMrFJHOTkfux8g18/2liT9fAEBeYRk/vmhMB1UkIhLikbuZTTOzTWaWZWazG9k+\nxcwOmdmq4M9d4S81MlU3l+5Bj7yzpQMqERE5qsVwN7MY4HHgEmAccJWZjWuk6ULn3MnBn/vCXGfE\nOjLzwHWnN7zvqoiIV0I5cp8EZDnntjnnyoGXgMvbt6zoceTA/YTBvZptN/3Rhfxx0XaqNA+NiHSA\nUMJ9MJBT6/Gu4Lr6zjCzNWb2ppmd0NgLmdn1ZpZpZpl5eXltKDfyOAJhbcCXT2nsnyVg3e4C7n1j\nPX/7JKfJNiIi4RKuq2VWAMOccycBjwKvNdbIOTfHOZfhnMtISUkJ01t7KzEuBoD42C78/Esn8sPz\nRzXbfnXOQf61andHlCYinVgo4b4bGFrr8ZDguhrOuQLnXFFweR4QZ2bJYasygv1s2lhmTRnJZeMH\n0j0hllunHtds+79l5vCjl1Z1UHUi0lmFEu6fAKPNLN3M4oEZwOu1G5jZALPAnLhmNin4ugfCXWwk\n6tU1jp9OG0tsTOs+BGnsXUTaU4vXuTvnKs3sB8BbQAzwrHPuUzO7Ibj9KeArwEwzqwQOAzOcC+Ea\nQZ96+5ZzOFBcTp9u8Vz82w8bbTPy9nlkDO/DP2ae0cHViUhnENKXmIJDLfPqrXuq1vJjwGPhLS16\njU7twejgcnxslya/oZq543Oy9hUyqn+PjitORDoFTT/QztL7dW92+4UPf8g/lu8ir7Cs2XYiIq1h\nXo2eZGRkuMzMTE/euyPlFZaxcEseP355dUjtN//8Ev7z6V4uGNuf7gmaHUJE6jKz5c65jJba6ci9\nnaX0SOCKU4eE3P5n/1zDTS+u5M7X1rVjVSLidwr3CPPqysBVpq+s3M03nl5KQWkFmdn5HlclItFG\nwzIdZO2uQxw6XMFZo5NJmz035OeNHdCDjXsL2fi/02q+MCUinZeGZSLM+CG9OGt04Htda+6ZGvLz\nNu4tBHRdvIi0js7YeaBnYlyrn7O3oJRl2/MZ0CuR845r/AYhIiJHKNw9Mu+ms6moqmbdZ4e449WW\nT55e8OsPapazH7wMgEff2cKfl2Qz96azSe2Z2F6likgU0pi7x5xzpN82j9mXjOXBNzeG9Jze3eI4\nWFJRZ92RwBcRf9OYe5QwM7IfvIwbzh3Jsjsu4MoQLpusH+wAL2fmUFxW2R4likgUUrhHkP49Evn1\n1ybw1++d1urn/vQfa/jFvA3tUJWIRCOFewQ6Y2Qyb99yDgt/eh7bH7g05Of99eOdpM2eyx8WbgOg\noLSCC379Put2H2qvUkUkQumEaoQanXp0MrHUnglcNWkYa3Yd4t2N+1p87s/nbuCPi7IB2H3wML95\nezPPfPMLAJRWVJFXWMbQvt3apW4RiQw6oRpFDpVUMOG++W1+/vPfmcQ1zywDYOv9lxLTxYDASd03\n1+1l6rjUVs9LLyIdSydUfahHYuCD1pdOHtSm5x8JdoAT736LtNlzcc7xyordzHphBX/4aHuLr/Hc\nkmzSZs+lrLKqTTWISMfQkXuUyskvYe3uQ8x6YcUxvU7XuBgOVwSCeni/brx76xRiuhg7D5QwrF83\nZsxZQnpyEg9cMZ773ljPs4sCfwBW3HkRfbvHH3M/RKR1Qj1y15h7lBratxtD+3bjZ9PG8tySbOJj\nu7DjQEmrX+dIsAPsOFDCyNuP3pPlD9dmsHRbPku35fPAFeNrgh0CQzkiErk0LBPlZk4ZyZLbLsCC\nj2d8YSh9usVx/thjn6Lgu881/clq4s8X8Ph7Wfzm7c3ceIyfHkQk/BTuPnHDuSMBuHP6OFbeNZXL\n2zgu35TGZrJ86K1N/O6dLcxdu4dNwQnOCksr+MnfV5NbUNqq16+udqz/rCAstYqIwt03ZkwaRvaD\nl9XcvSk9OXB7vy+fMpiVd15EctLR8fH7vzw+7O8//dGFVFU7xt8zn78v38Vp979TZ3tRWSV//Xgn\ni7L2N/r8x9/L4tJHFrJ2l67JFwkHnVD1se37i0nr1w0zo7iskn2FZTWh/8T7WQzomRjy7f/a4sLj\nU7n/yyeSEBfD1N98QG5B4D6x9efB2XGgmHMfeh+Ar2UM4VdfmVBn+5ceX8SEIb249/ITgcAfioLD\nFQzq3bXFGtJmz+WrE4fw0FcnNNuuqtpRWlGlWxtKxNMJVakJcoDuCbGk1wquWVNGAVBeWc3sV9a2\ny/sv2JDLgg25Dda/t3EfZ49OZvv+YorLq/jS44tqtr2cuYuZU0bVqX1VzkFW5Rzke+eMYF9hGVc8\nsRiAf//wLLqYMW5Qz2br+PvyXUyfMIgTBvUkOSmh0TZ3/WsdL3y8k6xfXKJr/cUXdOQuALyzIZcV\nOz/n8fe2Mrh3V9659VzG3vkfkpMS+Ohn5/HUB1v57YItQGBc/4snDeS1Vbu5f15oM1m21lNXT2TC\n0F4sWJ/Lnf/6tNm22Q9exvrPCjh+YA/MrM622ucKxqQmMf+WcwGY9cJylmw9wMq7AjdOGX3HPCqq\nnO54JRFPR+7SKhccn8q5Y1LYvr+YWVNGkRgXw7I7LiAhNobEuBhuvnAMN184ps5zrj09rd3C/Ya/\nLA+57fXPZTJ/feATwriBPRnZP4mrTxtW5zJPgM25RfzqPxvJSOvDvLV762w7coxT7RzZ+4sZHhzO\nEolWOnKXY7JhTwHJSQmk9EhgxpwlLN2Wz08uPo5Th/XhqqeXel1ei84encz154yo+fbu366fzNfn\nLOXcMSk8cMV41u4+xClDe9O/jTdDyS0oZdfnJUwc3jecZUsnFuqRu8JdwuZAURl/XJTNLReNqZm3\n5s7X1vH80h0eV3ZskpPi+f01Gby4bCcXnzCAiqpqzjuuP13jA8M3K3d+TlxMFy5/fBHfO3sEsy8Z\nW/Pck++bz8GSijpz+RSVVXLyvfP52/cnK/Sl1RTuEhGqqx2/XbCZ/JJyvjFpOKP6J3Htsx+zdFs+\nyUnxfO/sEfx5cTY3XTCaGZOGccera3nh451elx2SayYP5+/LcyitqK6z/jdfn8Atf1vNE//v1AbT\nQzx9bQb/89pacgvKSEqIZd29FwNQXFbJ4Yoqqp1j1c6DdE+IZXRqEnM+2MbsS8Y2epJ376FSCkor\nGBOcQfSN1Z/RLT6GC45PbaceSyRQuEvEqqp23P36Or539giG9+veYHvWvkIufPjDRp87cXgfbrpg\nNB9uzuOZECY6i3TfPSud3t3i+L/5mxtsu2hcKm+vz+WaycPJ2lfE9AkD+fX8zdw6dQw780v4/QeB\nefuTk+K5depx3Ba86qn2pabV1Y51nx3ipCG9+f0HWzlzVDInDu5Vs905xxPvb+XKU4cwoFfTQ0+L\nt+7nmYXbefLqidz1r3VMP2kQ89fv5e4vnsCBojIS4mI4UFTGiJSksPy75OSXMKRPV533aITCXaLe\n8h2fs6+glJkvrOCicak8/o1TiY89egRbWlFFVbVj0i8WMG5QT17+/ulUu8AtB29rp8s7o8G9/3UC\n44f04tF3tjCqfxJPL9zOA1eMr/NvMqBnInsLSrnkxAG8uW4vk9L78vL3T2/09dbsOsh/Pbao0W3d\n4mMoKT964vo3X5/AiOQkHn57Mx9szqtZv/2BS5sNauccm3OLuOnFldx+2fFc9+wy7po+jm+fld7a\n7jeqqKySxNguvrjMVeEundrj72UxMqU7Fx6fyuclFdzz+qcs3XaAySP78dhVp2BmPL90B3e+tq7m\nOUkJsRTVuw/tael9+Xh7fkeX75mZU0aSk1/C1ZOHM2NO+5wQ/+YZaUw7cQAL1udy43mjiIkxnl+y\ng4fe2gTAqcN6s2LnQQb2SuS8sf1Zuu0A2/KKa57/02nHcc3k4Yy/Zz7XnT685sttzUmbPZcvThjE\no1edQkVVNe9u3MfUcak1f3CeW5LNReNSGdir5S/GeU3hLtKCDzfnce2zgatkeiTG8qsrT2LmCyv4\nz81n07d7PAWHKxnVP4mS8kp+9NIqbrlwDMP7dWPa7z4kJ/9ws699yrDerNx5sCO60ekdGYYqKqvk\nF3PX8z+XjeP2V9cyIjmJKycOZlXOQX7w15UAfOvMtJq7lD337UlMSu/L/PW53PTiSo4f2JOvZwzh\nzFHJJMbFMOuFFfzpW18gLvhpsWdiXLN1lFdW8+a6PZwwqBdd42MoLqsktUcixeWVNd+mds6xKOsA\np4/sV3OCvbUU7iIh2LS3kDGpSa0a2y0uqyS3oJT3N+Vx+cmDKK2sJreglCueWMxPpx3HrCmjcM5R\nXF5FaUUVfbvF88T7WXXG1f92/WSe+mArH2/Pp6S8ivsuP4GrTxvOdX9cxsItjc+/I407Z0wKuz8v\nYWuto/tQ9O+RwL7CspDbX3v6cEamJDEpvS9jB/RgX2EZD765kYe/NoF9hWUN5lOCwPmQ/UXlLPjx\nOQzu3Y37523g+aU7GNKnKx/97PxW1XuEwl2kg23OLWRUShJdmjgiK6usoqi0kryiMsYOODplwt5D\npaT2TKj5A1NQWsH8T3P5ysQhvJyZw5pdB7ls/CD+snQH3z93BAvW5/Kds0fQq2sclVXVFJdX8bsF\nW5g5ZSQFpRUsytrP/qJyHnlnC988Iw0z+OOibPp1j+dAcTkA/brH8/INp/Ovlbt55N2ssPR//i3n\n8NWnlnDocEWd9avvmnpMt4f0o0G9Ell82wVteq7CXUQaOPL7XvuTyluf7uXlT3J4+toMHn03i8Vb\n93PN6cO58PhUNu4tpNo5rnhiMTeeN5LrTk/DAbs+P8yVTy7msW+cwoodB7n5otE1wxarcg4y8y/L\nef47k0hPTqoZfli2PZ/H38uqc6K1KXd/cRz3vrG+5vFd08fxv3PX45d7xCyafT6DQ5j4rjFhDXcz\nmwb8DogB/uCce7DedgtuvxQoAb7pnGv2Dg4Kd5HOxzlX84elutoxd+0eLh0/sOYPQE5+CbExVnNi\nM3t/MfsKy5iUHviyV0VVNbe/spYrJw5hUK+urPvsEJ9k59eMo78y6wx6JsaR83kJ/8jcxdy1e/jl\nleOZftIg3lj9GbNfWcuFx6dyyrDeNSdwh/Xtxs78o3cxe/raDDKz8/n9h9va3M+0ft3IbuLOaLdd\nMpbvB++/0BZhC3cziwE2AxcBu4BPgKucc+trtbkU+CGBcD8N+J1z7rTmXlfhLiLhUlhaQRezNk/Z\n/O7GXHomxrEtr5ivZgypM0SWFB9LSUUVuQWlDO7dlc8OHqaLGa+s3M2Jg3oydkBPuifE0CMxjs25\nhWzNK+LykwfzweY8Fm/dz9WnDeefK3bx2wVbeOCK8Vw1adgx9TWc4X46cI9z7uLg49sAnHMP1Grz\ne+B959yLwcebgCnOuT1Nva7CXUSk9UIN91Cu6B8M5NR6vCu4rrVtRESkg3To17XM7HozyzSzzLy8\nlk+qiIhI24QS7ruBobUeDwmua20bnHNznHMZzrmMlJSU1tYqIiIhCiXcPwFGm1m6mcUDM4DX67V5\nHbjWAiYDh5obbxcRkfbV4qll51ylmf0AeIvApZDPOuc+NbMbgtufAuYRuFImi8ClkN9qv5JFRKQl\nIV035JybRyDAa697qtayA24Mb2kiItJW0T//pYiINKBwFxHxIc/mljGzPKCtN9dMBvwydZ76Epn8\n0he/9APUlyOGO+davNzQs3A/FmaWGco3tKKB+hKZ/NIXv/QD1JfW0rCMiIgPKdxFRHwoWsN9jtcF\nhJH6Epn80he/9APUl1aJyjF3ERFpXrQeuYuISDOiLtzNbJqZbTKzLDOb7XU9LTGzbDNba2arzCwz\nuK6vmb1tZluC/+1Tq/1twb5tMrOLvasczOxZM9tnZutqrWt17WY2MfhvkGVmj1hr7kbdvn25x8x2\nB/fNquBNZyK6L2Y21MzeM7P1Zvapmf0ouD7q9kszfYnG/ZJoZsvMbHWwL/cG13u3X5xzUfNDYG6b\nrcAIIB5YDYzzuq4Was4Gkuut+xUwO7g8G/hlcHlcsE8JQHqwrzEe1n4OcCqw7lhqB5YBkwED3gQu\niZC+3AP8dyNtI7YvwEDg1OByDwJ3SRsXjfulmb5E434xICm4HAd8HKzHs/0SbUfuk4As59w251w5\n8BJwucc1tcXlwJ+Dy38GvlRr/UvOuTLn3HYCE7FN8qA+AJxzHwL59Va3qnYzGwj0dM4tdYH/c5+r\n9ZwO00RfmhKxfXHO7XHB+xM75wqBDQRujBN1+6WZvjQlkvvinHNFwYdxwR+Hh/sl2sI9Gu/45IAF\nZrbczK4Prkt1R6dE3gukBpejoX+trX1wcLn++kjxQzNbExy2OfKROSr6YmZpwCkEjhKjer/U6wtE\n4X4xsxgzWwXsA952znm6X6It3KPRWc65k4FLgBvN7JzaG4N/naPykqVorj3oSQJDfCcDe4Bfe1tO\n6MwsCfgncLNzrqD2tmjbL430JSr3i3OuKvi7PoTAUfiJ9bZ36H6JtnAP6Y5PkcQ5tzv4333AqwSG\nWXKDH78I/ndfsHk09K+1te8OLtdf7znnXG7wF7IaeJqjQ2AR3RcziyMQhi84514Jro7K/dJYX6J1\nvxzhnDs7OSgTAAABKUlEQVQIvAdMw8P9Em3hHspdoSKGmXU3sx5HloGpwDoCNV8XbHYd8K/g8uvA\nDDNLMLN0YDSBkyuRpFW1Bz+SFpjZ5OBZ/2trPcdTR37pgr5MYN9ABPcl+L7PABuccw/X2hR1+6Wp\nvkTpfkkxs97B5a7ARcBGvNwvHXlGORw/BO74tJnA2eU7vK6nhVpHEDgjvhr49Ei9QD/gHWALsADo\nW+s5dwT7tgkPriqpV/+LBD4WVxAY+/tOW2oHMgj8gm4FHiP45bkI6MvzwFpgTfCXbWCk9wU4i8BH\n+zXAquDPpdG4X5rpSzTul5OAlcGa1wF3Bdd7tl/0DVURER+KtmEZEREJgcJdRMSHFO4iIj6kcBcR\n8SGFu4iIDyncRUR8SOEuIuJDCncRER/6/xJWJ9+ht7yNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe6b4707ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
