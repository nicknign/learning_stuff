{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以google/seq2seq的 BasicDecoder + TrainingHelper为例看基本的seq2seq解码阶段的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/seq2seq2014.png)\n",
    "\n",
    "**Notation**：\n",
    "\n",
    "这个文件里面，我们把上面这个使用真实response作为输入的解码方法叫做**基本版**解码方法；将使用上一个时间的预测的词语作为下一个时间的输入的解码方法叫做**升级版**解码方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这里是lecture4_seq2seq_part2A里面实现基本版decoder功能的代码\n",
    "```python\n",
    "decode_params = basic_decoder.BasicDecoder.default_params()\n",
    "decode_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = decoder_hidden_units\n",
    "decode_params[\"max_decode_length\"] = 16\n",
    "decode_params\n",
    "\n",
    "decoder_inputs_embedded = tf.nn.embedding_lookup(input_embeddings, decoder_inputs)\n",
    "\n",
    "from seq2seq.contrib.seq2seq import helper as decode_helper\n",
    "with tf.name_scope('minibatch'):\n",
    "    helper_ = decode_helper.TrainingHelper(\n",
    "        inputs = decoder_inputs_embedded,\n",
    "        sequence_length = decoder_inputs_length)\n",
    "        \n",
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                       mode=mode,\n",
    "                                       vocab_size=vocab_size)\n",
    "                                       \n",
    "decoder_output, decoder_state = decoder_fn(encoder_output.final_state, helper_)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32), \n",
    "        logits=tf.transpose(decoder_output.logits, perm = [1, 0, 2]))\n",
    ")\n",
    "```\n",
    "\n",
    "#### 一些观察\n",
    "1. 输入的数据是batch-major，而输出的预测是time-major\n",
    "2. 我们通过decoder_helper输入了decoder_inputs_embedded，即，我们使用`\"<eos> + 真实的response\"`作为decoder的input，而不是使用上一个时间sample的词语作为下一个时间的输入\n",
    "3. 调用decoding对象时，使用两个Class： BasicDecoder()和TrainingHelper(),placeholder中的数据，`decoder_inputs_embedded, decoder_inputs_length`通过TraingHelper()传输给解码过程\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先来看一下`decoder_fn`,即`BasicDecoder`中的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/basic_decoder.png)\n",
    "\n",
    "1. 由`decoder_output, decoder_state = decoder_fn(encoder_output.final_state, helper_)`可知，BasicDecoder应该有一个`__call__()`函数调用decoding操作； 通过BasicDecoder --> RNNDecoder --> GraphModule这条继承关系，得知BasicDecoder的`__call__()`函数调用RnnDecoder的`_build()`函数\n",
    "2. 由`self.initialize`和`self.step`可知，`TrainingHelper`用来准备下一个时间（timestep）的 RNN cell 的输入（包括state 和 word)，即`(first_inputs, initial_state) in self.initialize(), (next_inputs, next_state) in self.step()`\n",
    "3. `self.step()`的操作包括\n",
    "  + 更新当前时间的Cell的状态， `self.cell(inputs, state)`\n",
    "  + 预测当前时间的单词,`logits` + `sample_ids`,在基本版的rnn decoder中，这个`sample_ids`只用作输出; 在升级版的rnn_decoder中，这个`sample_ids`还被用作下一个时间的输入词语；不论那个版本的rnn_decoder, `logits`都被用于计算loss\n",
    "  + 准备下一个时间的Rnn cell的输入状态+词语\n",
    "4. 看RnnDecoder这个Base class如何基于step()操作实现整个sequence的decoding操作:RnnDecoder._build()\n",
    "\n",
    "![alt text](figure/rnn_decoder.png)\n",
    "\n",
    "`_build`解码过程与`raw_rnn`的结构相似，由初始化和时间循环构成\n",
    "1. `_setup`初始化\n",
    "2. **iteration**,调用`contrib.seq2seq.decoder.dynamic_decode`实现循环过程，循环中的每一步执行上面的`step`操作\n",
    "  \n",
    "```python\n",
    "outputs, final_state = dynamic_decode(\n",
    "    decoder=self, # self.step() 通过self传递给decoder\n",
    "    output_time_major=True,\n",
    "    impute_finished=False,\n",
    "    maximum_iterations=maximum_iterations)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 然后看一下TrainingHelper如何处理RNNcell的输入输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/demo_helper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def _unstack_ta(inp):\n",
    "    return tensor_array_ops.TensorArray(\n",
    "        dtype=inp.dtype, size=array_ops.shape(inp)[0],\n",
    "        element_shape=inp.get_shape()[1:]).unstack(inp)\n",
    " \n",
    "\n",
    "class TrainingHelper(Helper):\n",
    "    \"\"\"A helper for use during training.  Only reads decoder inputs.\n",
    "    \n",
    "    Returned sample_ids are the argmax of the RNN output logits.\n",
    "    \"\"\"\n",
    "\n",
    "# Note-1. inputs,即decoder_inputs, 和 sequence_length， 即decoder_inputs_length\n",
    "# 是helper对象的property，BasicDecoder对象并不直接读入或处理这些数据\n",
    "def __init__(self, inputs, sequence_length, time_major=False, name=None):\n",
    "    \"\"\"Initializer.\n",
    "\n",
    "    Args:\n",
    "        inputs: A (structure of) input tensors.\n",
    "        sequence_length: An int32 vector tensor.\n",
    "        time_major: Python bool.  Whether the tensors in `inputs` are time major.\n",
    "          If `False` (default), they are assumed to be batch major.\n",
    "        name: Name scope for any created operations.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if `sequence_length` is not a 1D tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Note-2.处理decoder_input\n",
    "    # 这个Helper使用真实的回复作为解码阶段的输入，这个输入从Tensor的形式转化为TensorArray的形式\n",
    "    with ops.name_scope(name, \"TrainingHelper\", [inputs, sequence_length]):\n",
    "    inputs = ops.convert_to_tensor(inputs, name=\"inputs\")\n",
    "    # Note-2-continue. TensorArray 适用于time-major的数据的管理，\n",
    "    #  如果输入的数据是batch-major的话，需要转化为time-major\n",
    "    if not time_major:\n",
    "        inputs = nest.map_structure(_transpose_batch_time, inputs)\n",
    "    self._input_tas = nest.map_structure(_unstack_ta, inputs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    self._sequence_length = ops.convert_to_tensor(\n",
    "        sequence_length, name=\"sequence_length\")\n",
    "    if self._sequence_length.get_shape().ndims != 1:\n",
    "        raise ValueError(\n",
    "            \"Expected sequence_length to be a vector, but received shape: %s\" %\n",
    "            self._sequence_length.get_shape())\n",
    "\n",
    "    self._zero_inputs = nest.map_structure(\n",
    "        lambda inp: array_ops.zeros_like(inp[0, :]), inputs)\n",
    "\n",
    "    self._batch_size = array_ops.size(sequence_length)\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._batch_size\n",
    "    \n",
    "    # Note-3，通过这个class和下面的CustomHelper模版可知\n",
    "    # helper对象用来处理RNNcell的输出（e.g. sample),准备RNNcell的输入(e.g. next_inputs)\n",
    "    # 通过自定义helper对象，可以带来decoding过程的灵活性\n",
    "    # 通过step()里面调用helper对象间接处理RNNcell的输入，输出，提高BasicDecoder的通用程度\n",
    "    def initialize(self, name=None):\n",
    "        with ops.name_scope(name, \"TrainingHelperInitialize\"):\n",
    "            finished = math_ops.equal(0, self._sequence_length)\n",
    "            all_finished = math_ops.reduce_all(finished)\n",
    "            next_inputs = control_flow_ops.cond(\n",
    "                all_finished, lambda: self._zero_inputs,\n",
    "                lambda: nest.map_structure(lambda inp: inp.read(0), self._input_tas))\n",
    "        return (finished, next_inputs)\n",
    "\n",
    "    def sample(self, time, outputs, name=None, **unused_kwargs):\n",
    "        with ops.name_scope(name, \"TrainingHelperSample\", [time, outputs]):\n",
    "            sample_ids = math_ops.cast(\n",
    "                math_ops.argmax(outputs, axis=-1), dtypes.int32)\n",
    "        return sample_ids\n",
    "\n",
    "    # Note-4. 这里的next_inputs方法和第四节课的raw_rnn的例子非常接近\n",
    "    # * 通过比较当前时间和每个样本的预期长度上限确定是否结束了decoding过程\n",
    "    def next_inputs(self, time, outputs, state, name=None, **unused_kwargs):\n",
    "        \"\"\"next_inputs_fn for TrainingHelper.\"\"\"\n",
    "        with ops.name_scope(name, \"TrainingHelperNextInputs\",\n",
    "                            [time, outputs, state]):\n",
    "            next_time = time + 1\n",
    "            finished = (next_time >= self._sequence_length)\n",
    "            all_finished = math_ops.reduce_all(finished)\n",
    "            def read_from_ta(inp):\n",
    "                return inp.read(next_time)\n",
    "            next_inputs = control_flow_ops.cond(\n",
    "                all_finished, lambda: self._zero_inputs,\n",
    "                lambda: nest.map_structure(read_from_ta, self._input_tas))\n",
    "        return (finished, next_inputs, state)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class CustomHelper(Helper):\n",
    "    \"\"\"Base abstract class that allows the user to customize sampling.\"\"\"\n",
    "\n",
    "    def __init__(self, initialize_fn, sample_fn, next_inputs_fn):\n",
    "        \"\"\"Initializer.\n",
    "        \n",
    "        Args:\n",
    "            initialize_fn: callable that returns `(finished, next_inputs)` for the first iteration.\n",
    "            sample_fn: callable that takes `(time, outputs, state)` and emits tensor `sample_ids`.\n",
    "            next_inputs_fn: callable that takes `(time, outputs, state, sample_ids)` and emits `(finished, next_inputs, next_state)`.\n",
    "        \"\"\"\n",
    "        self._initialize_fn = initialize_fn\n",
    "        self._sample_fn = sample_fn\n",
    "        self._next_inputs_fn = next_inputs_fn\n",
    "        self._batch_size = None\n",
    "\n",
    "        @property\n",
    "        def batch_size(self):\n",
    "            if self._batch_size is None:\n",
    "                raise ValueError(\"batch_size accessed before initialize was called\")\n",
    "            return self._batch_size\n",
    "\n",
    "        def initialize(self, name=None):\n",
    "            with ops.name_scope(name, \"%sInitialize\" % type(self).__name__):\n",
    "                (finished, next_inputs) = self._initialize_fn()\n",
    "                if self._batch_size is None:\n",
    "                    self._batch_size = array_ops.size(finished)\n",
    "            return (finished, next_inputs)\n",
    "\n",
    "        def sample(self, time, outputs, state, name=None):\n",
    "            with ops.name_scope(\n",
    "                name, \"%sSample\" % type(self).__name__, (time, outputs, state)):\n",
    "            return self._sample_fn(time=time, outputs=outputs, state=state)\n",
    "            \n",
    "        def next_inputs(self, time, outputs, state, sample_ids, name=None):\n",
    "            with ops.name_scope(\n",
    "                name, \"%sNextInputs\" % type(self).__name__, (time, outputs, state)):\n",
    "                return self._next_inputs_fn(\n",
    "                    time=time, outputs=outputs, state=state, sample_ids=sample_ids)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 然后练习自定义helper实现升级版的decoding\n",
    "![alt text](figure/nct-seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案例学习：`ScheduledOutputTrainingHelper`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/scheduled_sampling.jpg)\n",
    "\n",
    "![alt text](figure/scheduled_sampling_2.jpg)\n",
    "\n",
    "reference: [Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks](https://arxiv.org/pdf/1506.03099.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class ScheduledOutputTrainingHelper(TrainingHelper):\n",
    "    \"\"\"A training helper that adds scheduled sampling directly to outputs.\n",
    "\n",
    "    Returns False for sample_ids where no sampling took place; True elsewhere.\n",
    "    \"\"\"\n",
    "\n",
    "def __init__(self, inputs, sequence_length, sampling_probability,\n",
    "             time_major=False, seed=None, next_input_layer=None,\n",
    "             auxiliary_inputs=None, name=None):\n",
    "    \"\"\"Initializer.\n",
    "    \n",
    "    Args:\n",
    "        inputs: A (structure) of input tensors.\n",
    "        sequence_length: An int32 vector tensor.\n",
    "        sampling_probability: A 0D `float32` tensor: the probability of sampling \n",
    "            from the outputs instead of reading directly from the inputs.\n",
    "        time_major: Python bool.  Whether the tensors in `inputs` are time major.\n",
    "            If `False` (default), they are assumed to be batch major.\n",
    "        seed: The sampling seed.\n",
    "        next_input_layer: (Optional) An instance of `tf.layers.Layer`, i.e.,\n",
    "            `tf.layers.Dense`.  Optional layer to apply to the RNN output to create\n",
    "            the next input.\n",
    "        auxiliary_inputs: An optional (structure of) auxiliary input tensors with\n",
    "            a shape that matches `inputs` in all but (potentially) the final\n",
    "            dimension. These tensors will be concatenated to the sampled output or\n",
    "            the `inputs` when not sampling for use as the next input.\n",
    "        name: Name scope for any created operations.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: if `sampling_probability` is not a scalar or vector.\n",
    "    \"\"\"\n",
    "    with ops.name_scope(name, \"ScheduledOutputTrainingHelper\",\n",
    "                        [inputs, auxiliary_inputs, sampling_probability]):\n",
    "        self._sampling_probability = ops.convert_to_tensor(\n",
    "            sampling_probability, name=\"sampling_probability\")\n",
    "        if self._sampling_probability.get_shape().ndims not in (0, 1):\n",
    "            raise ValueError(\n",
    "                \"sampling_probability must be either a scalar or a vector. \"\n",
    "                \"saw shape: %s\" % (self._sampling_probability.get_shape()))\n",
    "            \n",
    "        if auxiliary_inputs is None:\n",
    "            maybe_concatenated_inputs = inputs\n",
    "        else:\n",
    "            inputs = ops.convert_to_tensor(inputs, name=\"inputs\")\n",
    "        auxiliary_inputs = ops.convert_to_tensor(\n",
    "            auxiliary_inputs, name=\"auxiliary_inputs\")\n",
    "        maybe_concatenated_inputs = nest.map_structure(\n",
    "            lambda x, y: array_ops.concat((x, y), -1),\n",
    "            inputs, auxiliary_inputs)\n",
    "        if not time_major:\n",
    "            auxiliary_inputs = nest.map_structure(\n",
    "                _transpose_batch_time, auxiliary_inputs)\n",
    "            \n",
    "        self._auxiliary_input_tas = (\n",
    "            nest.map_structure(_unstack_ta, auxiliary_inputs)\n",
    "            if auxiliary_inputs is not None else None)\n",
    "        \n",
    "        self._seed = seed\n",
    "        if (next_input_layer is not None and not isinstance(next_input_layer,\n",
    "                                                            layers_base._Layer)):  # pylint: disable=protected-access\n",
    "            raise TypeError(\"next_input_layer must be a Layer, received: %s\" %\n",
    "                            type(next_input_layer))\n",
    "            self._next_input_layer = next_input_layer\n",
    "\n",
    "        super(ScheduledOutputTrainingHelper, self).__init__(\n",
    "            inputs=maybe_concatenated_inputs,\n",
    "            sequence_length=sequence_length,\n",
    "            time_major=time_major,\n",
    "            name=name)\n",
    "\n",
    "def initialize(self, name=None):\n",
    "    return super(ScheduledOutputTrainingHelper, self).initialize(name=name)\n",
    "\n",
    "def sample(self, time, outputs, state, name=None):\n",
    "    with ops.name_scope(name, \"ScheduledOutputTrainingHelperSample\",\n",
    "                        [time, outputs, state]):\n",
    "        sampler = bernoulli.Bernoulli(probs=self._sampling_probability)\n",
    "    return math_ops.cast(\n",
    "        sampler.sample(sample_shape=self.batch_size, seed=self._seed),\n",
    "        dtypes.bool)\n",
    "\n",
    "def next_inputs(self, time, outputs, state, sample_ids, name=None):\n",
    "    with ops.name_scope(name, \"ScheduledOutputTrainingHelperNextInputs\",\n",
    "                        [time, outputs, state, sample_ids]):\n",
    "        (finished, base_next_inputs, state) = (\n",
    "            super(ScheduledOutputTrainingHelper, self).next_inputs(\n",
    "                time=time,\n",
    "                outputs=outputs,\n",
    "                state=state, \n",
    "                sample_ids=sample_ids,\n",
    "                name=name))\n",
    "        def maybe_sample():\n",
    "            \"\"\"Perform scheduled sampling.\"\"\"\n",
    "            \n",
    "            def maybe_concatenate_auxiliary_inputs(outputs_, indices=None):\n",
    "                \"\"\"Concatenate outputs with auxiliary inputs, if they exist.\"\"\"\n",
    "                if self._auxiliary_input_tas is None:\n",
    "                    return outputs_\n",
    "                \n",
    "                next_time = time + 1\n",
    "                auxiliary_inputs = nest.map_structure(\n",
    "                    lambda ta: ta.read(next_time), self._auxiliary_input_tas)\n",
    "                if indices is not None:\n",
    "                    auxiliary_inputs = array_ops.gather_nd(auxiliary_inputs, indices)\n",
    "                return nest.map_structure(\n",
    "                    lambda x, y: array_ops.concat((x, y), -1), \n",
    "                    outputs_, auxiliary_inputs)\n",
    "\n",
    "            if self._next_input_layer is None:\n",
    "                return array_ops.where(\n",
    "                    sample_ids, maybe_concatenate_auxiliary_inputs(outputs),\n",
    "                    base_next_inputs)\n",
    "\n",
    "            where_sampling = math_ops.cast(\n",
    "                array_ops.where(sample_ids), dtypes.int32)\n",
    "            where_not_sampling = math_ops.cast(\n",
    "                array_ops.where(math_ops.logical_not(sample_ids)), dtypes.int32)\n",
    "            outputs_sampling = array_ops.gather_nd(outputs, where_sampling)\n",
    "            inputs_not_sampling = array_ops.gather_nd(base_next_inputs,\n",
    "                                                      where_not_sampling)\n",
    "            sampled_next_inputs = maybe_concatenate_auxiliary_inputs(\n",
    "                self._next_input_layer(outputs_sampling), where_sampling)\n",
    "\n",
    "            base_shape = array_ops.shape(base_next_inputs)\n",
    "            return (array_ops.scatter_nd(indices=where_sampling,\n",
    "                                         updates=sampled_next_inputs,\n",
    "                                         shape=base_shape)\n",
    "                    + array_ops.scatter_nd(indices=where_not_sampling,\n",
    "                                           updates=inputs_not_sampling,\n",
    "                                           shape=base_shape))\n",
    "\n",
    "    all_finished = math_ops.reduce_all(finished)\n",
    "    next_inputs = control_flow_ops.cond(\n",
    "        all_finished, lambda: base_next_inputs, maybe_sample)\n",
    "    return (finished, next_inputs, state)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
