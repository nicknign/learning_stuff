{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演示seq2seq lib中的beam search使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('/home/dong/Dropbox/Projects/NLP/seq2seq')\n",
    "from seq2seq.encoders import rnn_encoder\n",
    "from seq2seq.decoders import (basic_decoder, beam_search_decoder)\n",
    "\n",
    "from seq2seq.inference import beam_search\n",
    "from seq2seq.models import bridges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 产生 demo 合成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生7个长度不一（最短3，最长8）的sequences, 其中前十个是:\n",
      "[6, 6, 3, 5, 8, 2, 6]\n",
      "[8, 9, 5, 7]\n",
      "[4, 3, 2]\n",
      "[2, 2, 7]\n",
      "[5, 4, 7, 9, 5]\n",
      "[8, 6, 9, 4]\n",
      "[3, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 16\n",
    "\n",
    "encoder_hidden_units = 32\n",
    "decoder_hidden_units = encoder_hidden_units\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 7\n",
    "\n",
    "# 一个generator，每次产生一个minibatch的随机样本\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('产生%d个长度不一（最短3，最长8）的sequences, 其中前十个是:' % batch_size)\n",
    "for seq in next(batches)[:min(batch_size, 10)]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义使用beamsearch decoder的seq2seq模型\n",
    "\n",
    "### 声明placholder和定义encoder部分，同part2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating UnidirectionalRNNEncoder in mode=infer\n",
      "INFO:tensorflow:\n",
      "UnidirectionalRNNEncoder:\n",
      "  init_scale: 0.04\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.INFER\n",
    "\n",
    "# 数据部分：\n",
    "# 1-a. 声明placeholder\n",
    "with tf.name_scope('encoder-in'):\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "with tf.name_scope('decoder-target'):\n",
    "    decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')\n",
    "    decoder_targets_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_targets_length')\n",
    "with tf.name_scope('decoder-input'):\n",
    "    decoder_inputs = tf.placeholder(shape=(None, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    decoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')\n",
    "\n",
    "# 1-b. 数据转化为embedding格式\n",
    "# input_embeddings: [vocab_size, input_embedding_size]\n",
    "# output_embeddings: [vocab_size, input_embedding_size]\n",
    "with tf.name_scope('embedding'):\n",
    "    input_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "    output_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, decoder_hidden_units], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "    \n",
    "\n",
    "with tf.name_scope('input-embeddings'):\n",
    "    encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        input_embeddings, encoder_inputs)\n",
    "\n",
    "# 2. 定义encoder\n",
    "# 2-a. encoder 超参数\n",
    "encoder_params = rnn_encoder.UnidirectionalRNNEncoder.default_params()\n",
    "encoder_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = encoder_hidden_units\n",
    "encoder_params[\"rnn_cell\"][\"cell_class\"] = \"BasicLSTMCell\"\n",
    "encoder_params\n",
    "\n",
    "# 2-b. 使用UnidirectionalRNNEncoder编码\n",
    "encode_fn = rnn_encoder.UnidirectionalRNNEncoder(\n",
    "    encoder_params, mode)\n",
    "encoder_output = encode_fn(\n",
    "    encoder_inputs_embedded, encoder_inputs_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/seq2seq_uniRNNencoder.png)\n",
    "UnidirectionalRNNEncoder\n",
    "\n",
    "![alt text](figure/seq2seq_biRNNencoder.png)\n",
    "BidirectionalRNNEncoder\n",
    "\n",
    "```\n",
    " /\\\n",
    "/  \\\n",
    " ||\n",
    "```\n",
    "由上面的seq2seq的源代码可见，使用dynamic_rnn或者其变种(bidirectional_dynamic_rnn)， encoder过程通常是简单直观的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义decoding模型，使用\n",
    "**seq2seq.decoders.beam_search_decoder.BeamSearchDecoder**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用BeamSearchDecoder需要定义两组超参数\n",
    "\n",
    "### 1. hyperparameter-group-1: \n",
    "**decoder RNN 的选项，任何基于RNN的decoding操作(e.g. BasicDecoder)都需要设定的超参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_scale': 0.04,\n",
       " 'max_decode_length': 100,\n",
       " 'rnn_cell': {'cell_class': 'BasicLSTMCell',\n",
       "  'cell_params': {'num_units': 32},\n",
       "  'dropout_input_keep_prob': 1.0,\n",
       "  'dropout_output_keep_prob': 1.0,\n",
       "  'num_layers': 1,\n",
       "  'residual_combiner': 'add',\n",
       "  'residual_connections': False,\n",
       "  'residual_dense': False}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_params = beam_search_decoder.BeamSearchDecoder.default_params()\n",
    "decode_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = decoder_hidden_units\n",
    "decode_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. hyperparameter-group-2\n",
    "\n",
    "**设置 beam_search 的选项，即针对 beam_search 操作的超参数**\n",
    "\n",
    "* beam_width\n",
    "* length_penalty_weight\n",
    "* choose_successors_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = beam_search.BeamSearchConfig(\n",
    "    beam_width = 3,\n",
    "    vocab_size = vocab_size,\n",
    "    eos_token = EOS,\n",
    "    length_penalty_weight = 0.6,\n",
    "    choose_successors_fn = beam_search.choose_top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个beam search设置的例子：\n",
    "\n",
    "| hyper-param | value | \n",
    "| ------------ | --------- | \n",
    "| beam_width | 10 |\n",
    "|vocab_size | 10 |\n",
    "|eos_token | 1 |\n",
    "|length_penalty_weight | 0.600000 |\n",
    "|choose_successors_fn | ```<function choose_top_k at 0x7f83ec705840>``` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/seq2seq-bs-length.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq.contrib.seq2seq import helper as decode_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/seq2seq-bs-decoder-in.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=infer\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n",
      "INFO:tensorflow:Creating BeamSearchDecoder in mode=infer\n",
      "INFO:tensorflow:\n",
      "BeamSearchDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 100\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 32}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_fn = basic_decoder.BasicDecoder(\n",
    "    params=decode_params,\n",
    "    mode=mode,\n",
    "    vocab_size=vocab_size)\n",
    "\n",
    "# initialize the BeamSearchDecoder\n",
    "# arguments:\n",
    "#   decoder: A instance of \"RNNDecoder\" to be used with beam search\n",
    "#   config: A \"BeamSearchConfig\" that defines beam search decoding parameters\n",
    "decoder_fn = beam_search_decoder.BeamSearchDecoder(\n",
    "    decoder=decoder_fn,\n",
    "    config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'forward_rnn_encoder/rnn/while/Exit_2:0' shape=(?, 32) dtype=float32>, h=<tf.Tensor 'forward_rnn_encoder/rnn/while/Exit_3:0' shape=(?, 32) dtype=float32>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "beam_helper = decode_helper.GreedyEmbeddingHelper(\n",
    "    embedding=output_embeddings,\n",
    "    start_tokens=tf.fill([config.beam_width], EOS),\n",
    "    end_token=EOS)\n",
    "\n",
    "#initial_state = bridge()\n",
    "initial_state = decoder_fn.cell.zero_state(batch_size, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'BasicLSTMCellZeroState/zeros:0' shape=(7, 32) dtype=float32>, h=<tf.Tensor 'BasicLSTMCellZeroState/zeros_1:0' shape=(7, 32) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'forward_rnn_encoder/rnn/while/Exit_2:0' shape=(?, 32) dtype=float32>, h=<tf.Tensor 'forward_rnn_encoder/rnn/while/Exit_3:0' shape=(?, 32) dtype=float32>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "decoder_output, _ = decoder_fn(encoder_output.final_state, beam_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalBeamDecoderOutput(predicted_ids=<tf.Tensor 'basic_decoder/ExpandDims_8:0' shape=(?, 1, 3) dtype=int32>, beam_search_output=BeamDecoderOutput(logits=<tf.Tensor 'basic_decoder/ExpandDims:0' shape=(?, 1, 3, 10) dtype=float32>, predicted_ids=<tf.Tensor 'basic_decoder/ExpandDims_1:0' shape=(?, 1, 3) dtype=int32>, log_probs=<tf.Tensor 'basic_decoder/ExpandDims_2:0' shape=(?, 1, 3) dtype=float32>, scores=<tf.Tensor 'basic_decoder/ExpandDims_3:0' shape=(?, 1, 3) dtype=float32>, beam_parent_ids=<tf.Tensor 'basic_decoder/ExpandDims_4:0' shape=(?, 1, 3) dtype=int32>, original_outputs=DecoderOutput(logits=<tf.Tensor 'basic_decoder/ExpandDims_5:0' shape=(?, 1, 3, 10) dtype=float32>, predicted_ids=<tf.Tensor 'basic_decoder/ExpandDims_6:0' shape=(?, 1, 3) dtype=int32>, cell_output=<tf.Tensor 'basic_decoder/ExpandDims_7:0' shape=(?, 1, 3, 32) dtype=float32>)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figure/seq2seq-helper.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
