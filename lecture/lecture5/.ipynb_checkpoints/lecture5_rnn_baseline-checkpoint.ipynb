{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('/home/dong/Dropbox/Projects/NLP/seq2seq')\n",
    "from seq2seq.encoders import rnn_encoder\n",
    "from seq2seq.decoders import basic_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from seq2seq.contrib.seq2seq import decoder as contrib_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 50\n",
    "\n",
    "# 第一层的encoder RNN cell 的 hidden_state_size\n",
    "encoder_hidden_units = 50\n",
    "\n",
    "# 与hred一致\n",
    "decoder_hidden_units = encoder_hidden_units * 2\n",
    "\n",
    "import helpers as data_helpers\n",
    "batch_size = 11\n",
    "round_num = 20\n",
    "\n",
    "# 一个generator，每次产生一个minibatch的随机样本\n",
    "\n",
    "batches = data_helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size*round_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "产生11组的sequences, \n",
      "每一组sequence包含20句长度不一（最短3，最长8）的sequence, \n",
      "其中前十组是:\n",
      "\n",
      "[[8, 3, 9, 9, 9, 8], [8, 6, 6, 2, 7, 4], [7, 4, 4, 8], [4, 7, 4], [6, 8, 8, 9], [6, 5, 2], [4, 6, 4, 8, 2, 3, 7], [4, 2, 5, 8, 9, 6], [5, 8, 4, 2], [2, 2, 5, 4, 3], [6, 5, 4, 3], [4, 2, 2, 8, 3, 3, 6, 4], [6, 9, 8, 9, 6, 3, 6], [6, 5, 2, 5, 8], [9, 7, 8, 3, 2], [5, 5, 4, 7, 4], [9, 8, 2, 3, 5, 7, 9], [9, 5, 2, 7, 6, 8, 4], [8, 5, 8, 8, 4, 9, 6, 7], [3, 2, 4, 6]]\n",
      "\n",
      "[[5, 9, 3, 6, 8, 6, 6, 5], [9, 7, 6, 3], [4, 7, 7], [7, 7, 9, 2, 8], [4, 3, 9, 5, 5, 9], [8, 6, 8, 6], [7, 9, 9, 2, 8, 2], [3, 2, 7, 6, 7], [9, 6, 4, 4, 3], [8, 5, 7, 7, 5], [2, 6, 8, 6, 2, 4, 7, 3], [3, 7, 6, 5, 3, 7], [2, 5, 7, 3, 5, 8, 8, 2], [3, 9, 7, 3, 2, 7, 4, 3], [5, 8, 7, 4, 8, 5, 4], [3, 6, 5, 7, 4], [2, 7, 6, 8], [4, 5, 9, 4, 9], [7, 3, 9, 8, 6], [3, 4, 4, 9]]\n",
      "\n",
      "[[4, 7, 2, 6, 2, 5, 3, 5], [2, 4, 7, 2], [3, 5, 4, 4, 6, 9, 2], [9, 5, 6, 6, 7], [6, 6, 2, 5, 9], [8, 4, 5, 6, 4, 6, 6, 9], [8, 6, 4, 4, 3], [6, 4, 6], [5, 3, 3, 9], [2, 9, 5, 5], [9, 3, 6, 5, 3, 5, 7, 4], [8, 9, 5, 8, 8, 8, 8], [3, 2, 6, 5, 8, 4, 6], [9, 9, 8, 7, 3, 9], [7, 3, 6, 7, 8, 4, 2], [7, 5, 5, 9, 8, 8], [7, 3, 9, 9], [2, 2, 9, 6, 7], [7, 9, 6, 5, 3, 3, 7, 4], [3, 4, 7, 6, 5]]\n",
      "\n",
      "[[8, 9, 6], [2, 9, 8], [2, 5, 9, 8], [8, 4, 8, 9, 7, 4], [6, 2, 4, 9, 7, 7, 8, 2], [8, 5, 2, 5, 4, 9, 9], [8, 3, 7, 3, 4, 4, 6, 3], [3, 6, 8, 4], [8, 2, 6, 9, 9, 6, 3], [9, 7, 8, 7, 2, 8], [6, 7, 7, 4, 9, 5, 7], [3, 5, 3, 3, 5, 2, 8, 8], [5, 3, 7, 8, 4, 3, 7, 3], [9, 3, 8, 7], [7, 2, 8, 6, 8], [4, 3, 9, 8, 3, 8], [7, 3, 7, 2, 6, 3], [5, 7, 4, 5, 8, 6, 9], [3, 9, 2], [2, 3, 3, 7]]\n",
      "\n",
      "[[9, 4, 2], [5, 9, 8, 9, 9, 4, 7], [7, 4, 4, 2, 3, 2], [7, 9, 7, 5], [4, 5, 3, 7, 5, 5], [5, 3, 8], [3, 7, 6, 5, 4, 7, 4], [4, 3, 2, 5, 8, 2, 7], [3, 8, 5, 2, 9, 4, 2, 9], [4, 9, 9, 3, 9, 9, 9, 2], [2, 8, 5, 2, 7, 5], [8, 6, 5], [6, 7, 7], [4, 5, 8, 3], [7, 2, 7, 4, 9], [7, 3, 8, 3], [4, 4, 8, 5, 9], [2, 4, 5, 2, 6, 3, 7, 8], [3, 6, 3, 3, 2, 3], [5, 5, 5, 7]]\n",
      "\n",
      "[[4, 2, 2, 2], [9, 7, 4, 5, 8], [9, 8, 9, 2, 8], [2, 7, 6], [6, 5, 7, 2, 7, 7, 4], [2, 9, 5], [5, 9, 8, 3, 3], [6, 3, 9, 3, 2, 2, 9], [2, 5, 5, 7, 6], [9, 9, 4], [8, 8, 4, 3, 2], [8, 7, 9, 9], [4, 4, 2, 4], [5, 9, 3, 2, 8], [7, 4, 6, 8, 6, 8], [4, 6, 7, 3], [9, 9, 4, 6, 5, 8, 6, 6], [7, 8, 7, 7, 9], [6, 4, 4, 9, 4, 4, 5, 2], [4, 9, 4]]\n",
      "\n",
      "[[3, 8, 4, 3, 9, 5], [4, 3, 5], [9, 8, 5, 9, 4, 9, 8], [8, 3, 2, 7, 2, 5, 9], [3, 7, 5, 7], [3, 3, 9, 8], [2, 8, 6, 5, 4, 4], [2, 4, 7], [6, 6, 9, 5], [4, 3, 8, 6, 9, 9, 6], [2, 2, 3, 7, 3, 6, 7, 8], [5, 9, 5, 2, 4, 4, 2], [3, 3, 8, 8, 6, 6, 6], [5, 7, 9, 8], [3, 4, 2, 9, 8], [5, 6, 6, 2, 2, 5], [5, 3, 7], [7, 4, 5, 8, 9, 8, 9], [8, 7, 8], [5, 5, 7]]\n",
      "\n",
      "[[3, 8, 6, 7, 3], [2, 5, 7, 9], [2, 2, 9, 2], [5, 9, 8, 3], [2, 9, 5, 3, 2, 6], [9, 8, 6, 8, 8, 6, 7], [2, 8, 7, 3, 9, 5, 5, 8], [3, 9, 3, 6, 3, 2], [3, 6, 3], [8, 5, 7, 4, 8, 8, 9, 3], [6, 9, 8, 4, 4, 5, 7, 3], [2, 5, 9, 6, 9], [5, 3, 9, 8], [5, 2, 3, 6, 5, 6, 2, 6], [9, 3, 4, 6, 3, 5, 3], [4, 5, 2], [6, 6, 9, 5, 2, 7, 8], [3, 5, 6, 4, 3, 5, 5, 3], [7, 3, 5, 3, 3, 4, 8], [2, 9, 2, 8, 2, 6, 6]]\n",
      "\n",
      "[[5, 9, 9, 7], [2, 6, 6], [2, 3, 6, 4, 5, 5, 8, 9], [7, 2, 5, 3, 5, 4], [7, 2, 8, 9, 2, 2], [9, 7, 2, 8, 2, 6], [6, 4, 7, 8], [4, 3, 9, 8], [6, 2, 6, 8, 6], [8, 9, 3, 5, 6, 6, 3, 3], [2, 7, 9, 9, 7, 5, 2], [4, 8, 3, 3, 5, 9, 8], [9, 5, 8, 9, 4, 3, 2], [7, 2, 3, 2, 4, 5, 5], [9, 3, 4, 3, 5, 4, 6, 4], [2, 7, 6], [8, 8, 7, 3, 6, 3, 6], [6, 2, 8, 4], [2, 4, 7, 7], [8, 8, 8, 8, 8, 8, 5, 9]]\n",
      "\n",
      "[[4, 5, 9], [2, 9, 4, 3, 4, 9, 4], [9, 9, 6, 4, 8, 9], [4, 5, 4, 6, 5], [5, 3, 6, 4, 8], [3, 7, 4, 5], [3, 5, 6, 5], [5, 6, 5, 4], [6, 9, 6, 3], [6, 2, 9, 4, 3], [7, 4, 4, 7, 4, 7, 3, 8], [7, 4, 3, 9], [9, 3, 2, 3, 3, 9], [6, 8, 9, 4, 8, 8, 4, 4], [7, 3, 2], [2, 2, 3, 3, 6, 3], [4, 9, 7, 6, 3, 3], [9, 2, 8, 2, 7, 9, 8], [2, 5, 4, 6, 4, 9, 9, 8], [8, 7, 3, 6, 8, 9]]\n",
      "\n",
      "[[2, 7, 4], [4, 4, 3, 5], [9, 8, 8, 8, 2, 6], [5, 8, 4], [4, 9, 8, 9, 3, 8, 2], [7, 3, 8, 3], [9, 8, 5, 4, 2], [5, 5, 4, 7, 3, 7, 2, 6], [5, 9, 3, 5, 5, 6, 2], [7, 6, 2, 4, 3, 4, 5], [5, 3, 5], [7, 9, 7, 3], [8, 9, 5], [5, 2, 2, 2], [3, 2, 8], [6, 5, 9, 9, 5], [6, 6, 6, 5, 8], [3, 6, 4, 5], [8, 6, 6, 9], [3, 8, 5, 5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def demo_mult_rounds(batches, batch_size, round_num):\n",
    "    data = next(batches)\n",
    "    mb = list()\n",
    "    id = 0\n",
    "    for i in range(batch_size):\n",
    "        mb.append([])\n",
    "        for j in range(round_num):\n",
    "            mb[-1].append(data[id])\n",
    "            id += 1\n",
    "    return mb\n",
    "\n",
    "print('产生%d组的sequences, \\n'\n",
    "      '每一组sequence包含%d句长度不一（最短3，最长8）的sequence, \\n'\n",
    "      '其中前十组是:\\n' % (batch_size, round_num))\n",
    "\n",
    "for seq in demo_mult_rounds(batches, batch_size, round_num):\n",
    "    print('%s\\n' % seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生轮数为20的合成数据\n",
    "\n",
    "#### 使用连续20个sequence模拟一个轮数为20的对话数据\n",
    "\n",
    "#### 第i-轮的decoder输出是从第1句到第i-句输入的拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('minibatch_encoder'):\n",
    "    # 一个 minibatch 包含 batch_size * round_num 个 sequences\n",
    "    encoder_inputs = tf.placeholder(shape=(batch_size*round_num, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(batch_size*round_num,),\n",
    "                                           dtype=tf.int32,\n",
    "                                           name='encoder_inputs_length')\n",
    "with tf.name_scope('minibatch-decoder'):\n",
    "    decoder_targets = tf.placeholder(shape=(batch_size*round_num, None),\n",
    "                                     dtype=tf.int32,\n",
    "                                     name='decoder_targets')\n",
    "    \n",
    "    decoder_inputs = tf.placeholder(shape=(batch_size*round_num, None),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name='decoder_inputs')\n",
    "    decoder_inputs_length = tf.placeholder(shape=(batch_size*round_num,),\n",
    "                                            dtype=tf.int32,\n",
    "                                            name='decoder_inputs_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_scale': 0.04,\n",
       " 'rnn_cell': {'cell_class': 'BasicLSTMCell',\n",
       "  'cell_params': {'num_units': 50},\n",
       "  'dropout_input_keep_prob': 1.0,\n",
       "  'dropout_output_keep_prob': 1.0,\n",
       "  'num_layers': 2,\n",
       "  'residual_combiner': 'add',\n",
       "  'residual_connections': False,\n",
       "  'residual_dense': False}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个句子encoding的超参数\n",
    "encoder_params = rnn_encoder.StackBidirectionalRNNEncoder.default_params()\n",
    "encoder_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = encoder_hidden_units\n",
    "encoder_params[\"rnn_cell\"][\"cell_class\"] = \"BasicLSTMCell\"\n",
    "encoder_params[\"rnn_cell\"][\"num_layers\"] = 2\n",
    "encoder_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating StackBidirectionalRNNEncoder in mode=train\n",
      "INFO:tensorflow:\n",
      "StackBidirectionalRNNEncoder:\n",
      "  init_scale: 0.04\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 50}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 2\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 第一层 embedding\n",
    "with tf.name_scope('embedding'):\n",
    "    input_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0),\n",
    "        dtype=tf.float32)\n",
    "\n",
    "mode = tf.contrib.learn.ModeKeys.TRAIN\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "    input_embeddings, encoder_inputs)\n",
    "encode_fn = rnn_encoder.StackBidirectionalRNNEncoder(\n",
    "    encoder_params, mode)\n",
    "encoder_output = encode_fn(\n",
    "    encoder_inputs_embedded, encoder_inputs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: <tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_1/concat:0' shape=(220, ?, 100) dtype=float32>\n",
      "\n",
      "\n",
      "final state: ((LSTMStateTuple(c=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_0/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 50) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_1/bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_1/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 50) dtype=float32>)), (LSTMStateTuple(c=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_0/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 50) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_1/bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_1/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 50) dtype=float32>)))\n",
      "\n",
      "\n",
      "attention values: <tf.Tensor 'stacked_bidi_rnn_encoder/stack_bidirectional_rnn/cell_1/concat:0' shape=(220, ?, 100) dtype=float32>\n"
     ]
    }
   ],
   "source": [
    "print('outputs: %s\\n\\n' % repr(encoder_output.outputs))\n",
    "print('final state: %s\\n\\n' % repr(encoder_output.final_state))\n",
    "print('attention values: %s' % repr(encoder_output.attention_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 处理第一层encoder的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_output.final_state[0][1].c, \n",
    "     encoder_output.final_state[1][1].c), \n",
    "    1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_output.final_state[0][1].h,\n",
    "     encoder_output.final_state[1][1].h),\n",
    "    1)\n",
    "\n",
    "encoder_final_state = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'concat:0' shape=(?, 100) dtype=float32>, h=<tf.Tensor 'concat_1:0' shape=(?, 100) dtype=float32>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoding阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 准备新的输入\n",
    "from seq2seq.contrib.seq2seq import helper as decode_helper\n",
    "with tf.name_scope('decoder_input'):\n",
    "    decoder_inputs_embedded = tf.nn.embedding_lookup(\n",
    "        input_embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('decoder_helper'):\n",
    "    helper_ = decode_helper.TrainingHelper(\n",
    "        inputs = decoder_inputs_embedded,\n",
    "        sequence_length = decoder_inputs_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init_scale': 0.04,\n",
       " 'max_decode_length': 225,\n",
       " 'rnn_cell': {'cell_class': 'BasicLSTMCell',\n",
       "  'cell_params': {'num_units': 100},\n",
       "  'dropout_input_keep_prob': 1.0,\n",
       "  'dropout_output_keep_prob': 1.0,\n",
       "  'num_layers': 1,\n",
       "  'residual_combiner': 'add',\n",
       "  'residual_connections': False,\n",
       "  'residual_dense': False}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_params = basic_decoder.BasicDecoder.default_params()\n",
    "decode_params[\"rnn_cell\"][\"cell_params\"][\"num_units\"] = decoder_hidden_units\n",
    "decode_params[\"max_decode_length\"] = batch_size * round_num + 5\n",
    "\n",
    "decode_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BasicDecoder in mode=train\n",
      "INFO:tensorflow:\n",
      "BasicDecoder:\n",
      "  init_scale: 0.04\n",
      "  max_decode_length: 225\n",
      "  rnn_cell:\n",
      "    cell_class: BasicLSTMCell\n",
      "    cell_params: {num_units: 100}\n",
      "    dropout_input_keep_prob: 1.0\n",
      "    dropout_output_keep_prob: 1.0\n",
      "    num_layers: 1\n",
      "    residual_combiner: add\n",
      "    residual_connections: false\n",
      "    residual_dense: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder_fn = basic_decoder.BasicDecoder(params=decode_params,\n",
    "                                        mode=mode,\n",
    "                                        vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_state = decoder_fn(\n",
    "    encoder_final_state,\n",
    "    helper_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = tf.constant(\n",
    "    [[x] for x in range(round_num-1, batch_size*round_num, round_num)],\n",
    "    dtype=tf.int32)\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=tf.one_hot(tf.gather_nd(params = decoder_targets,\n",
    "                                       indices = indices),\n",
    "                          depth=vocab_size, dtype=tf.float32),\n",
    "        logits=tf.gather_nd(params = tf.transpose(decoder_output.logits,\n",
    "                                         perm = [1, 0, 2]),\n",
    "                           indices = indices)\n",
    "    )\n",
    ")\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dong/Dropbox/Projects/NLP/sequence2sequence/tf-seq2seq-devel/arch_basic_rnn/model.ckpt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "log_path = '/home/dong/Dropbox/Projects/NLP/sequence2sequence/tf-seq2seq-devel/arch_basic_rnn'\n",
    "summary_writer = tf.summary.FileWriter(log_path, sess.graph)\n",
    "\n",
    "\n",
    "# 保存模型\n",
    "# word2vec参数的单词和词向量部分分别保存到了metadata和ckpt文件里面\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(log_path, \"model.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = next(batches)\n",
    "\n",
    "cumbatch = []\n",
    "for i in range(len(batch)):\n",
    "    if i%round_num==0:\n",
    "        cumbatch.append(batch[i])\n",
    "    else:\n",
    "        cumbatch.append(batch[i] + cumbatch[-1])\n",
    "\n",
    "encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(batch)\n",
    "decoder_targets_, _ = data_helpers.batch(\n",
    "    [(sequence) + [EOS] for sequence in cumbatch]\n",
    ")\n",
    "decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "    [[EOS] + (sequence) for sequence in cumbatch]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 9, 5, ..., 0, 0, 0],\n",
       "       [1, 4, 6, ..., 0, 0, 0],\n",
       "       [1, 6, 9, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 2, 8, ..., 0, 0, 0],\n",
       "       [1, 9, 2, ..., 0, 0, 0],\n",
       "       [1, 2, 4, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets_.T\n",
    "decoder_inputs_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "\n",
    "    cumbatch = []\n",
    "    for i in range(len(batch)):\n",
    "        if i%round_num==0:\n",
    "            cumbatch.append(batch[i])\n",
    "        else:\n",
    "            cumbatch.append(batch[i] + cumbatch[-1])\n",
    "\n",
    "    encoder_inputs_, encoder_inputs_length_ = data_helpers.batch(cumbatch)\n",
    "    decoder_targets_, _ = data_helpers.batch(\n",
    "        [(sequence) + [EOS] for sequence in cumbatch]\n",
    "    )\n",
    "    decoder_inputs_, decoder_inputs_length_ = data_helpers.batch(\n",
    "        [[EOS] + (sequence) for sequence in cumbatch]\n",
    "    )    \n",
    "    # 在feedDict里面，key可以是一个Tensor\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_.T,\n",
    "        decoder_inputs: decoder_inputs_.T,\n",
    "        decoder_targets: decoder_targets_.T,\n",
    "        encoder_inputs_length: encoder_inputs_length_,\n",
    "        decoder_inputs_length: decoder_inputs_length_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_track = []\n",
    "fd = next_feed()\n",
    "_, l = sess.run([train_op, loss], fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch [[9, 5, 7, 6, 2, 7, 6, 7], [4, 6, 7, 2], [6, 9, 9, 5, 9, 4, 3, 4], [9, 3, 7], [6, 8, 6], [7, 2, 9, 3], [9, 2, 5, 5], [6, 3, 9], [5, 8, 7, 6, 6, 9, 4, 4], [4, 2, 9, 2, 8, 3, 3, 8], [7, 2, 4, 7], [5, 9, 6, 6, 7, 9], [2, 5, 8], [9, 9, 8, 4, 3, 3, 4], [9, 8, 9, 6, 5, 8], [7, 9, 9, 3, 3, 5], [8, 5, 3, 5, 3, 9, 2, 7], [6, 5, 6, 4, 6, 5, 9], [5, 4, 5], [9, 8, 7, 2, 7, 5, 7, 6], [4, 7, 3, 9, 3, 9, 5], [2, 2, 8], [2, 7, 5, 5, 3, 9], [8, 5, 3, 2, 6, 7, 6], [5, 8, 6, 9, 6, 4], [9, 9, 5, 6], [9, 6, 4, 8], [4, 5, 4], [5, 3, 5, 5, 9, 9], [4, 5, 5, 8, 8, 9, 9, 3], [3, 4, 6, 2, 2, 7], [8, 5, 3, 3, 5, 9, 7, 6], [8, 8, 5, 7, 4], [6, 4, 9, 9, 4, 7, 5, 2], [7, 7, 4, 7, 9, 2, 4], [3, 6, 7, 9, 2], [8, 2, 2, 2, 8, 7, 9], [8, 5, 2, 7, 2, 8, 4, 6], [5, 7, 9, 3, 9, 5, 6, 9], [8, 3, 6, 4, 2, 7, 8], [3, 6, 9, 8, 3], [5, 9, 7], [9, 3, 7, 2, 5, 9, 3], [5, 5, 8, 5], [3, 5, 3, 3, 4, 9, 7], [7, 4, 9], [8, 8, 6, 9, 4], [9, 3, 8, 7, 6], [8, 8, 8], [2, 3, 7, 7, 5], [5, 9, 3], [2, 9, 5, 2, 7, 4, 4, 2], [2, 3, 5], [9, 9, 6, 9, 5, 5, 9], [9, 3, 9, 2, 3, 2], [6, 8, 9], [5, 2, 5, 8, 5], [6, 9, 9], [2, 7, 6, 7, 9, 3, 9, 8], [5, 7, 5], [2, 6, 9], [8, 3, 8, 7, 7, 8], [6, 5, 9], [7, 5, 8, 9, 5, 5, 3, 8], [5, 3, 5, 9, 9, 3], [7, 9, 8, 6], [5, 8, 2, 5], [8, 4, 5, 5, 4, 3, 2], [7, 7, 9, 7, 8, 9, 9], [3, 2, 9, 6, 6, 9, 4], [7, 3, 3, 2, 6, 7, 6], [7, 9, 9, 9, 9], [8, 3, 7, 5, 6, 9, 4, 8], [3, 7, 9, 3, 9, 7], [5, 5, 5, 9, 9, 3, 9], [3, 8, 6, 8, 5, 9, 3, 8], [7, 6, 2, 2, 8, 6, 4], [4, 8, 5], [3, 3, 8, 3], [4, 3, 9, 3, 9, 2, 4], [4, 8, 9, 3, 8, 4], [8, 7, 6, 2, 5, 7, 9, 4], [2, 2, 3, 9, 9, 4, 8], [6, 8, 4], [7, 8, 5, 4, 3, 8], [4, 4, 5, 6, 8, 4], [6, 6, 9, 9, 9], [5, 8, 7, 8, 8], [9, 7, 5, 2], [6, 5, 3, 7], [9, 5, 2, 3, 7, 4, 6, 7], [7, 5, 8, 9], [2, 2, 3], [7, 5, 6, 3, 9, 4], [9, 8, 3, 2, 2, 9, 2], [8, 4, 3, 4], [8, 8, 3, 9, 5, 6, 8, 2], [2, 2, 3, 7, 2, 8, 2, 2], [8, 6, 2, 4, 9, 2, 4, 3], [2, 7, 3, 8, 8], [2, 9, 7, 9, 7], [2, 2, 2, 5, 9], [4, 9, 6, 5, 8, 2, 7, 9], [8, 5, 9, 2, 8, 7, 2], [2, 6, 3, 3, 2, 5, 8], [6, 4, 8, 2, 5, 4], [8, 4, 4, 3, 5, 9, 5], [5, 3, 2], [3, 6, 5, 6, 4], [8, 5, 4, 4, 5, 8, 7, 9], [3, 8, 6, 8], [8, 8, 9, 6, 8], [8, 6, 3, 5, 4, 5, 6, 2], [9, 5, 8, 9, 8, 9, 9], [9, 3, 8, 2, 7], [3, 5, 8, 2, 6, 6, 5], [7, 8, 8, 2], [3, 8, 9, 3, 2], [7, 9, 6], [6, 2, 6, 2, 8, 8, 8], [2, 6, 8, 6], [5, 8, 5], [4, 4, 3, 6, 9], [8, 8, 6, 4, 7, 9], [2, 7, 8, 2, 8], [3, 5, 8], [5, 3, 5, 5, 8, 4, 7], [7, 5, 7, 7, 6], [2, 5, 5, 8, 5, 8], [4, 7, 4, 7], [4, 4, 7, 9], [3, 8, 4, 6], [7, 6, 9, 7], [7, 3, 8, 3, 4, 9], [2, 5, 9, 5, 3, 5], [5, 8, 9, 6], [3, 2, 3, 8, 6, 9, 5, 7], [2, 3, 9, 7], [3, 3, 6], [4, 2, 8, 6, 7, 4], [2, 6, 6, 3, 7, 8], [7, 6, 5, 6, 7], [3, 4, 5], [8, 8, 5], [7, 9, 8], [9, 4, 5, 2, 8, 6, 3, 9], [7, 5, 4, 9, 2, 3, 3], [3, 9, 4, 2, 9], [3, 5, 7], [9, 6, 9, 4, 5, 5, 7, 8], [6, 9, 8, 3, 5, 6], [3, 8, 7], [9, 9, 8, 5, 5, 2], [5, 6, 8], [6, 8, 8, 3, 2, 6, 6, 8], [7, 9, 4], [2, 6, 9], [8, 4, 9, 2, 3, 8, 6, 9], [8, 6, 4, 3, 5, 7, 2, 2], [4, 4, 6, 6, 3, 2, 8, 3], [3, 7, 3, 9, 6], [8, 2, 6, 4, 9, 6, 8], [2, 5, 3, 7, 7, 9, 4], [7, 7, 7, 3], [4, 2, 3, 9, 9, 7], [4, 2, 2], [8, 7, 5, 4, 9], [3, 2, 4, 5, 4], [3, 8, 9, 8, 5, 9], [5, 8, 2, 5], [3, 4, 6, 2, 5, 6], [7, 4, 8, 3, 6, 2, 3, 7], [8, 4, 3, 3, 7], [6, 8, 5, 2, 3, 4, 2, 8], [8, 3, 2, 4, 2, 5], [4, 7, 4, 7, 9], [2, 4, 3, 6, 6], [8, 7, 7], [8, 9, 4], [8, 5, 8, 6, 9], [5, 4, 9, 4, 3], [4, 6, 7, 8, 9, 9, 2], [7, 2, 3], [2, 6, 5, 7, 4, 5], [9, 9, 9], [4, 2, 6, 2, 8, 5, 9, 4], [7, 7, 8, 9, 5, 2, 8], [5, 5, 7, 4, 5, 9], [3, 4, 4], [6, 2, 5], [5, 8, 8, 9, 6], [5, 7, 5, 6, 4, 3, 4], [9, 5, 5, 3, 5], [9, 2, 7, 8, 6, 4, 8], [9, 2, 2, 9, 2], [6, 6, 6, 2, 7, 6, 3], [4, 8, 6, 7, 3], [3, 2, 8, 4], [6, 3, 8, 7, 7, 8, 9, 2], [8, 4, 6, 7, 5, 2, 2, 2], [3, 5, 7], [7, 8, 6, 7], [7, 5, 2, 8, 7, 5, 7, 3], [4, 3, 3, 9, 4], [9, 5, 3], [3, 4, 9, 5, 8, 8, 6], [5, 9, 5], [2, 8, 8, 9, 8, 3, 9], [4, 4, 9, 3, 6, 6], [8, 7, 9, 3, 7, 9, 8], [9, 4, 3, 7, 5], [8, 7, 5], [2, 5, 5, 9, 2, 7], [7, 3, 7, 8], [7, 4, 3, 9, 3, 8, 3], [3, 9, 4], [3, 9, 5, 7], [2, 8, 3, 2, 4, 5, 2, 2], [9, 2, 6, 8], [2, 4, 8, 8, 5, 6, 8, 5]]\n",
      "  minibatch loss: 2.2564096450805664\n",
      "  sample 1:\n",
      "    targets     > [3 6 9 6 4 9 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [1 6 6 3 6 6 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 9 3 8 3 5 7 3 9 9 6 8 3 6 9 6 4 9 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [1 6 6 6 3 3 2 2 9 3 3 3 3 3 3 3 3 6 3 3 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('batch {}'.format(batch))\n",
    "print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "predict_ = sess.run(decoder_output.predicted_ids, fd)\n",
    "for i, (inp, targ, pred) in enumerate(\n",
    "    zip(fd[encoder_inputs], \n",
    "        fd[decoder_targets], \n",
    "        predict_.T)):\n",
    "    if i in [0, 2]:\n",
    "        print('  sample {}:'.format(i + 1))\n",
    "        print('    targets     > {}'.format(targ))\n",
    "        print('    predicted > {}'.format(pred))\n",
    "    if i == round_num-1:\n",
    "        break\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.2096989154815674\n",
      "  sample 1:\n",
      "    targets     > [8 7 3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [1 9 5 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 7 5 3 7 4 9 7 9 3 6 6 8 7 3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [1 6 6 8 2 9 6 3 5 5 3 3 6 9 5 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 100\n",
      "  minibatch loss: 1.9925100803375244\n",
      "  sample 1:\n",
      "    targets     > [6 2 4 5 8 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "    predicted > [2 2 2 6 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [3 5 6 2 8 9 8 8 2 2 4 6 2 4 5 8 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "    predicted > [2 2 2 2 2 2 2 2 2 2 6 8 8 6 8 4 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 1.7801780700683594\n",
      "  sample 1:\n",
      "    targets     > [5 6 9 5 4 6 2 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 5 5 5 5 5 9 9 9 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [3 2 5 4 9 7 8 6 8 4 4 5 4 8 5 6 9 5 4 6 2 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 4 4 4 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 7 6 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 300\n",
      "  minibatch loss: 1.7994502782821655\n",
      "  sample 1:\n",
      "    targets     > [2 5 6 5 8 3 7 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [2 5 3 5 4 6 6 3 4 5 7 6 2 5 6 5 8 3 7 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 1.7518913745880127\n",
      "  sample 1:\n",
      "    targets     > [9 5 2 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 5 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [9 4 6 8 2 9 5 7 4 4 7 9 5 2 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 4 9 9 9 9 4 4 4 4 9 9 4 4 4 9 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 1.7935341596603394\n",
      "  sample 1:\n",
      "    targets     > [3 9 2 9 8 8 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "    predicted > [3 9 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [9 7 5 2 7 3 8 6 8 4 8 8 3 9 2 9 8 8 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "    predicted > [7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 1.7581489086151123\n",
      "  sample 1:\n",
      "    targets     > [2 6 8 4 9 6 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [2 6 8 4 9 6 8 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 2 7 7 4 6 3 6 2 6 8 4 9 6 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [7 7 7 4 2 6 2 2 2 8 8 8 8 8 8 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 700\n",
      "  minibatch loss: 1.7122695446014404\n",
      "  sample 1:\n",
      "    targets     > [4 6 8 9 8 4 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 8 8 9 8 4 3 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 4 9 9 8 3 3 4 9 4 6 8 9 8 4 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 9 9 9 3 3 4 4 9 4 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 1.6306906938552856\n",
      "  sample 1:\n",
      "    targets     > [5 6 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 3 3 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 3 9 5 7 4 9 9 5 7 3 5 6 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 4 9 5 7 9 9 5 5 5 5 5 5 9 9 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 900\n",
      "  minibatch loss: 1.6471450328826904\n",
      "  sample 1:\n",
      "    targets     > [7 3 8 9 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "    predicted > [3 3 8 9 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [7 7 6 4 6 4 2 2 5 4 8 2 2 6 7 3 8 9 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "    predicted > [7 6 6 6 6 2 2 2 2 2 2 2 6 6 7 8 9 9 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 1.6012859344482422\n",
      "  sample 1:\n",
      "    targets     > [9 3 8 4 7 5 7 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 3 7 7 7 5 7 7 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [6 6 8 3 4 9 6 7 6 8 4 6 5 9 3 8 4 7 5 7 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [6 6 8 6 9 9 6 6 6 4 4 5 5 9 7 7 7 7 5 7 7 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1100\n",
      "  minibatch loss: 1.642343282699585\n",
      "  sample 1:\n",
      "    targets     > [9 7 3 5 7 6 7 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "    predicted > [9 7 3 5 7 7 7 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 6 8 4 2 4 7 2 3 6 9 7 3 5 7 6 7 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "    predicted > [4 4 4 4 2 2 2 2 3 6 7 7 7 7 7 7 7 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "\n",
      "batch 1200\n",
      "  minibatch loss: 1.6125160455703735\n",
      "  sample 1:\n",
      "    targets     > [8 3 8 7 5 5 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [8 3 8 5 5 5 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [5 8 9 9 9 6 3 9 5 9 8 3 8 7 5 5 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 9 9 9 6 6 3 9 5 8 8 3 5 5 5 5 3 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1300\n",
      "  minibatch loss: 1.4088120460510254\n",
      "  sample 1:\n",
      "    targets     > [7 4 2 5 4 2 3 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [7 4 2 5 4 2 3 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 5 6 2 9 5 7 4 2 5 4 2 3 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 5 6 9 9 5 5 4 5 5 4 2 3 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1400\n",
      "  minibatch loss: 1.4831657409667969\n",
      "  sample 1:\n",
      "    targets     > [9 8 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 8 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [9 3 5 6 4 2 4 7 3 2 4 6 9 8 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 5 5 4 4 2 4 2 2 2 4 9 9 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 1.5498014688491821\n",
      "  sample 1:\n",
      "    targets     > [5 4 8 9 9 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 4 9 9 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [6 5 9 5 3 5 4 4 5 6 7 6 8 7 5 4 8 9 9 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 5 5 5 5 5 4 6 6 6 7 7 7 7 5 9 9 9 7 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1600\n",
      "  minibatch loss: 1.5159528255462646\n",
      "  sample 1:\n",
      "    targets     > [9 5 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 5 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 2 3 3 4 5 5 4 4 8 8 4 2 6 2 3 9 5 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [3 3 3 3 4 5 4 4 4 8 2 2 2 2 2 9 5 5 5 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1700\n",
      "  minibatch loss: 1.4722850322723389\n",
      "  sample 1:\n",
      "    targets     > [4 7 9 6 3 3 9 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 9 9 3 3 3 9 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [3 9 3 4 4 8 8 3 6 4 7 9 6 3 3 9 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [3 9 3 4 8 8 8 4 4 4 9 9 6 3 9 9 8 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1800\n",
      "  minibatch loss: 1.4540836811065674\n",
      "  sample 1:\n",
      "    targets     > [9 6 4 5 5 2 7 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 6 5 5 5 2 7 7 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [2 9 7 6 3 6 8 4 8 5 3 4 9 6 4 5 5 2 7 7 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [2 9 6 6 3 8 8 4 8 5 4 4 6 6 5 5 5 7 7 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 1900\n",
      "  minibatch loss: 1.4982179403305054\n",
      "  sample 1:\n",
      "    targets     > [5 2 9 6 5 8 8 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 2 9 6 5 8 9 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [6 8 6 8 7 7 3 6 8 6 7 7 8 6 5 2 9 6 5 8 8 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [6 8 6 7 7 7 3 6 7 7 7 7 8 6 5 9 9 8 8 8 8 9 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 1.4541606903076172\n",
      "  sample 1:\n",
      "    targets     > [9 4 5 9 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 4 5 9 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [2 3 3 7 4 7 7 2 3 7 9 4 5 9 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [3 3 3 7 7 7 7 2 3 9 9 5 5 9 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2100\n",
      "  minibatch loss: 1.41422438621521\n",
      "  sample 1:\n",
      "    targets     > [6 9 4 3 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [6 9 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [3 8 4 2 5 7 8 8 2 6 6 9 4 3 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [3 8 2 2 8 8 8 8 2 6 9 9 3 3 3 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2200\n",
      "  minibatch loss: 1.4505871534347534\n",
      "  sample 1:\n",
      "    targets     > [8 9 9 9 8 2 7 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [8 9 9 9 8 2 9 9 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 6 4 7 6 2 6 9 2 4 9 3 4 8 9 9 9 8 2 7 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [6 6 6 6 6 6 6 9 9 4 9 3 9 9 9 9 9 2 2 9 9 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2300\n",
      "  minibatch loss: 1.3497517108917236\n",
      "  sample 1:\n",
      "    targets     > [7 2 7 4 8 5 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [7 2 7 4 8 5 3 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [4 5 9 2 5 2 4 5 8 7 2 7 4 8 5 3 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 5 9 2 5 2 5 5 8 7 2 5 5 8 5 3 9 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2400\n",
      "  minibatch loss: 1.4741837978363037\n",
      "  sample 1:\n",
      "    targets     > [5 7 2 4 4 7 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 7 2 4 4 7 8 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [9 6 3 6 7 8 9 8 3 7 5 2 5 5 7 2 4 4 7 8 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "    predicted > [9 6 3 6 8 8 8 8 3 5 5 5 5 5 7 2 4 7 7 8 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2500\n",
      "  minibatch loss: 1.3259106874465942\n",
      "  sample 1:\n",
      "    targets     > [9 4 4 7 8 6 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [4 4 4 7 6 6 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [5 5 6 7 4 5 4 4 8 3 7 8 8 9 4 4 7 8 6 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [5 5 6 4 4 5 4 4 8 3 8 8 4 4 4 7 7 8 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2600\n",
      "  minibatch loss: 1.399024248123169\n",
      "  sample 1:\n",
      "    targets     > [3 6 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [3 6 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [2 7 7 2 3 7 2 4 7 8 9 3 6 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [2 7 7 2 7 7 2 4 8 8 9 2 2 2 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2700\n",
      "  minibatch loss: 1.440414547920227\n",
      "  sample 1:\n",
      "    targets     > [6 6 7 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [6 6 2 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [3 9 8 7 9 9 7 7 3 2 2 6 6 7 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [3 9 8 9 9 9 7 7 2 2 2 6 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2800\n",
      "  minibatch loss: 1.366105079650879\n",
      "  sample 1:\n",
      "    targets     > [8 8 5 8 2 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [8 8 5 8 2 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [8 2 6 6 3 2 9 7 2 8 8 5 8 2 9 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [6 6 6 6 3 2 9 7 2 8 8 5 2 2 9 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 2900\n",
      "  minibatch loss: 1.2954727411270142\n",
      "  sample 1:\n",
      "    targets     > [8 8 9 2 5 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [8 8 9 2 5 5 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [8 7 2 6 5 8 2 8 4 8 5 9 4 8 8 9 2 5 5 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [7 7 2 6 5 8 2 8 4 5 5 9 5 5 5 5 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 1.3580294847488403\n",
      "  sample 1:\n",
      "    targets     > [2 8 9 6 8 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [2 8 9 6 8 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    targets     > [2 3 4 2 6 6 3 7 9 3 4 5 3 2 8 9 6 8 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "    predicted > [2 3 4 6 6 6 3 9 9 3 5 5 3 9 9 9 6 3 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 100\n",
    "\n",
    "try:\n",
    "    # 一个epoch的learning\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_output.predicted_ids, fd)\n",
    "            for i, (inp, targ, pred) in enumerate(\n",
    "                zip(fd[encoder_inputs], \n",
    "                    fd[decoder_targets], \n",
    "                    predict_.T)):\n",
    "                if i in [0, round_num-1]:\n",
    "                    print('  sample {}:'.format(i + 1))\n",
    "                    print('    targets     > {}'.format(targ))\n",
    "                    print('    predicted > {}'.format(pred))\n",
    "                if i == round_num-1:\n",
    "                    break\n",
    "            print()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.3925 after 33011 examples (batch_size=11)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwZ2IKAIxuBMRRSAGdyKiCPT/QpXB9JQ4RfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb338239198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
